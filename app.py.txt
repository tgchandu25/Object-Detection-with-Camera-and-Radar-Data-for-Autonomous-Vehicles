### Objective-1 - Developing an unimodal Object Detection system for
Autonomous Vehicles with Camera data
## Importing Libraries
import numpy as np
import os
import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score,
recall_score, f1_score, confusion_matrix
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
import seaborn as sns
## 1. Load and Preprocess the Data
## Data Preprocessing
def preprocess_image(image_path, img_size=(128, 128)):
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image = cv2.resize(image, img_size)
image = image / 255.0 # Normalize pixel values
return image
camera_images_path = 'E:/Data' # Use your dataset path
image_paths = [os.path.join(camera_images_path, img) for img in
os.listdir(camera_images_path)]
camera_data = np.array([preprocess_image(img_path) for img_path in
image_paths])
-------------------------------------------------------------------------error
Traceback (most recent call
last)
Cell In[8], line 10
8 camera_images_path = 'E:/Data' # Use your dataset path
9 image_paths = [os.path.join(camera_images_path, img) for img
in os.listdir(camera_images_path)]
---> 10 camera_data = np.array([preprocess_image(img_path) for
img_path in image_paths])
Cell In[8], line 3, in preprocess_image(image_path, img_size)
1 def preprocess_image(image_path, img_size=(128, 128)):
2
image = cv2.imread(image_path)
----> 3
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
4
image = cv2.resize(image, img_size)

5

image = image / 255.0

# Normalize pixel values

error: OpenCV(4.10.0) D:\a\opencv-python\opencv-python\opencv\modules\
imgproc\src\color.cpp:196: error: (-215:Assertion failed) !
_src.empty() in function 'cv::cvtColor'
import os
camera_images_path = 'E:/Data/sequence_01/camera' # Update the path
to your actual dataset structure
image_paths = [os.path.join(camera_images_path, img) for img in
os.listdir(camera_images_path)]
# Check if there are valid image files in the directory
if not image_paths:
print("No images found in the specified directory.")
else:
print(f"Found {len(image_paths)} images.")
Found 1402 images.
# Load one image and check
sample_image_path = image_paths[0]
image = cv2.imread(sample_image_path)
if image is None:
print(f"Failed to load the image at {sample_image_path}.")
else:
print(f"Successfully loaded image: {sample_image_path}")
Successfully loaded image: E:/Data/sequence_01/camera\156859092964.jpg
camera_data = []
failed_images = []
for img_path in image_paths:
image = cv2.imread(img_path)
if image is None:
failed_images.append(img_path)
continue
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image = cv2.resize(image, (128, 128))
image = image / 255.0
camera_data.append(image)
camera_data = np.array(camera_data)
print(f"Loaded {len(camera_data)} images successfully.")
if failed_images:
print(f"Failed to load {len(failed_images)} images.")

Loaded 1402 images successfully.
image_extensions = ('.jpg', '.jpeg', '.png') # Add other extensions
if necessary
image_paths = [os.path.join(camera_images_path, img) for img in
os.listdir(camera_images_path) if
img.lower().endswith(image_extensions)]
# Dummy labels (0 or 1) for now (Replace with your actual object
detection labels)
labels = np.random.randint(0, 2, size=(len(camera_data),))
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(camera_data,
labels, test_size=0.2, random_state=42)
print(f"Training data shape: {X_train.shape}")
print(f"Testing data shape: {X_test.shape}")
Training data shape: (1121, 128, 128, 3)
Testing data shape: (281, 128, 128, 3)
## 2. Build and Compile the Model
## A. Model Setup with ResNet50
# Load ResNet50 with pre-trained weights
base_model = ResNet50(input_shape=(128, 128, 3), include_top=False,
weights='imagenet')
# Add custom layers on top of the base model
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)
classification (0 or 1)

# Binary

# Define the full model
model = Model(inputs=base_model.input, outputs=predictions)
# Freeze the base model layers
for layer in base_model.layers:
layer.trainable = False
# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy',
metrics=['accuracy'])
model.summary()

# Display the model architecture

Model: "functional"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━
━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)
┃ Output Shape
┃
Param # ┃ Connected to
┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━
━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)
│ (None, 128, 128, 3)
│
0 │ │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv1_pad (ZeroPadding2D)
│ (None, 134, 134, 3)
│
0 │ input_layer[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv1_conv (Conv2D)
│ (None, 64, 64, 64)
│
9,472 │ conv1_pad[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv1_bn (BatchNormalization) │ (None, 64, 64, 64)
│
256 │ conv1_conv[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv1_relu (Activation)
│ (None, 64, 64, 64)
│
0 │ conv1_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ pool1_pad (ZeroPadding2D)
│ (None, 66, 66, 64)
│
0 │ conv1_relu[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ pool1_pool (MaxPooling2D)
│ (None, 32, 32, 64)
│
0 │ pool1_pad[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_1_conv (Conv2D) │ (None, 32, 32, 64)
│
4,160 │ pool1_pool[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_1_bn
│ (None, 32, 32, 64)
│
256 │ conv2_block1_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_1_relu
│ (None, 32, 32, 64)
│
0 │ conv2_block1_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ conv2_block1_2_conv (Conv2D) │ (None, 32, 32, 64)
│
36,928 │ conv2_block1_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_2_bn
│ (None, 32, 32, 64)
│
256 │ conv2_block1_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_2_relu
│ (None, 32, 32, 64)
│
0 │ conv2_block1_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_0_conv (Conv2D) │ (None, 32, 32, 256)
│
16,640 │ pool1_pool[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_3_conv (Conv2D) │ (None, 32, 32, 256)
│
16,640 │ conv2_block1_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_0_bn
│ (None, 32, 32, 256)
│
1,024 │ conv2_block1_0_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_3_bn
│ (None, 32, 32, 256)
│
1,024 │ conv2_block1_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_add (Add)
│ (None, 32, 32, 256)
│
0 │ conv2_block1_0_bn[0][0],
│
│
│
│
│ conv2_block1_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block1_out (Activation) │ (None, 32, 32, 256)
│
0 │ conv2_block1_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block2_1_conv (Conv2D) │ (None, 32, 32, 64)
│
16,448 │ conv2_block1_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ conv2_block2_1_bn
│ (None, 32, 32, 64)
│
256 │ conv2_block2_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block2_1_relu
│ (None, 32, 32, 64)
│
0 │ conv2_block2_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block2_2_conv (Conv2D) │ (None, 32, 32, 64)
│
36,928 │ conv2_block2_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block2_2_bn
│ (None, 32, 32, 64)
│
256 │ conv2_block2_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block2_2_relu
│ (None, 32, 32, 64)
│
0 │ conv2_block2_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block2_3_conv (Conv2D) │ (None, 32, 32, 256)
│
16,640 │ conv2_block2_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block2_3_bn
│ (None, 32, 32, 256)
│
1,024 │ conv2_block2_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block2_add (Add)
│ (None, 32, 32, 256)
│
0 │ conv2_block1_out[0][0],
│
│
│
│
│ conv2_block2_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block2_out (Activation) │ (None, 32, 32, 256)
│
0 │ conv2_block2_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_1_conv (Conv2D) │ (None, 32, 32, 64)
│
16,448 │ conv2_block2_out[0][0]
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_1_bn
│ (None, 32, 32, 64)
│
256 │ conv2_block3_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_1_relu
│ (None, 32, 32, 64)
│
0 │ conv2_block3_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_2_conv (Conv2D) │ (None, 32, 32, 64)
│
36,928 │ conv2_block3_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_2_bn
│ (None, 32, 32, 64)
│
256 │ conv2_block3_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_2_relu
│ (None, 32, 32, 64)
│
0 │ conv2_block3_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_3_conv (Conv2D) │ (None, 32, 32, 256)
│
16,640 │ conv2_block3_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_3_bn
│ (None, 32, 32, 256)
│
1,024 │ conv2_block3_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_add (Add)
│ (None, 32, 32, 256)
│
0 │ conv2_block2_out[0][0],
│
│
│
│
│ conv2_block3_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv2_block3_out (Activation) │ (None, 32, 32, 256)
│
0 │ conv2_block3_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ conv3_block1_1_conv (Conv2D) │ (None, 16, 16, 128)
│
32,896 │ conv2_block3_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_1_bn
│ (None, 16, 16, 128)
│
512 │ conv3_block1_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_1_relu
│ (None, 16, 16, 128)
│
0 │ conv3_block1_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_2_conv (Conv2D) │ (None, 16, 16, 128)
│
147,584 │ conv3_block1_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_2_bn
│ (None, 16, 16, 128)
│
512 │ conv3_block1_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_2_relu
│ (None, 16, 16, 128)
│
0 │ conv3_block1_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_0_conv (Conv2D) │ (None, 16, 16, 512)
│
131,584 │ conv2_block3_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_3_conv (Conv2D) │ (None, 16, 16, 512)
│
66,048 │ conv3_block1_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_0_bn
│ (None, 16, 16, 512)
│
2,048 │ conv3_block1_0_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_3_bn
│ (None, 16, 16, 512)
│
2,048 │ conv3_block1_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_add (Add)
│ (None, 16, 16, 512)
│
0 │ conv3_block1_0_bn[0][0],
│
│
│
│
│ conv3_block1_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block1_out (Activation) │ (None, 16, 16, 512)
│
0 │ conv3_block1_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_1_conv (Conv2D) │ (None, 16, 16, 128)
│
65,664 │ conv3_block1_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_1_bn
│ (None, 16, 16, 128)
│
512 │ conv3_block2_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_1_relu
│ (None, 16, 16, 128)
│
0 │ conv3_block2_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_2_conv (Conv2D) │ (None, 16, 16, 128)
│
147,584 │ conv3_block2_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_2_bn
│ (None, 16, 16, 128)
│
512 │ conv3_block2_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_2_relu
│ (None, 16, 16, 128)
│
0 │ conv3_block2_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_3_conv (Conv2D) │ (None, 16, 16, 512)
│
66,048 │ conv3_block2_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_3_bn
│ (None, 16, 16, 512)
│
2,048 │ conv3_block2_3_conv[0][0] │

│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_add (Add)
│ (None, 16, 16, 512)
│
0 │ conv3_block1_out[0][0],
│
│
│
│
│ conv3_block2_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block2_out (Activation) │ (None, 16, 16, 512)
│
0 │ conv3_block2_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block3_1_conv (Conv2D) │ (None, 16, 16, 128)
│
65,664 │ conv3_block2_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block3_1_bn
│ (None, 16, 16, 128)
│
512 │ conv3_block3_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block3_1_relu
│ (None, 16, 16, 128)
│
0 │ conv3_block3_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block3_2_conv (Conv2D) │ (None, 16, 16, 128)
│
147,584 │ conv3_block3_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block3_2_bn
│ (None, 16, 16, 128)
│
512 │ conv3_block3_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block3_2_relu
│ (None, 16, 16, 128)
│
0 │ conv3_block3_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block3_3_conv (Conv2D) │ (None, 16, 16, 512)
│
66,048 │ conv3_block3_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ conv3_block3_3_bn
│ (None, 16, 16, 512)
│
2,048 │ conv3_block3_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block3_add (Add)
│ (None, 16, 16, 512)
│
0 │ conv3_block2_out[0][0],
│
│
│
│
│ conv3_block3_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block3_out (Activation) │ (None, 16, 16, 512)
│
0 │ conv3_block3_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_1_conv (Conv2D) │ (None, 16, 16, 128)
│
65,664 │ conv3_block3_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_1_bn
│ (None, 16, 16, 128)
│
512 │ conv3_block4_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_1_relu
│ (None, 16, 16, 128)
│
0 │ conv3_block4_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_2_conv (Conv2D) │ (None, 16, 16, 128)
│
147,584 │ conv3_block4_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_2_bn
│ (None, 16, 16, 128)
│
512 │ conv3_block4_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_2_relu
│ (None, 16, 16, 128)
│
0 │ conv3_block4_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_3_conv (Conv2D) │ (None, 16, 16, 512)
│
66,048 │ conv3_block4_2_relu[0][0] │

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_3_bn
│ (None, 16, 16, 512)
│
2,048 │ conv3_block4_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_add (Add)
│ (None, 16, 16, 512)
│
0 │ conv3_block3_out[0][0],
│
│
│
│
│ conv3_block4_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv3_block4_out (Activation) │ (None, 16, 16, 512)
│
0 │ conv3_block4_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_1_conv (Conv2D) │ (None, 8, 8, 256)
│
131,328 │ conv3_block4_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_1_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block1_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_1_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block1_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_2_conv (Conv2D) │ (None, 8, 8, 256)
│
590,080 │ conv4_block1_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_2_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block1_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_2_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block1_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ conv4_block1_0_conv (Conv2D) │ (None, 8, 8, 1024)
│
525,312 │ conv3_block4_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_3_conv (Conv2D) │ (None, 8, 8, 1024)
│
263,168 │ conv4_block1_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_0_bn
│ (None, 8, 8, 1024)
│
4,096 │ conv4_block1_0_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_3_bn
│ (None, 8, 8, 1024)
│
4,096 │ conv4_block1_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_add (Add)
│ (None, 8, 8, 1024)
│
0 │ conv4_block1_0_bn[0][0],
│
│
│
│
│ conv4_block1_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block1_out (Activation) │ (None, 8, 8, 1024)
│
0 │ conv4_block1_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block2_1_conv (Conv2D) │ (None, 8, 8, 256)
│
262,400 │ conv4_block1_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block2_1_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block2_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block2_1_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block2_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block2_2_conv (Conv2D) │ (None, 8, 8, 256)
│
590,080 │ conv4_block2_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ conv4_block2_2_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block2_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block2_2_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block2_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block2_3_conv (Conv2D) │ (None, 8, 8, 1024)
│
263,168 │ conv4_block2_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block2_3_bn
│ (None, 8, 8, 1024)
│
4,096 │ conv4_block2_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block2_add (Add)
│ (None, 8, 8, 1024)
│
0 │ conv4_block1_out[0][0],
│
│
│
│
│ conv4_block2_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block2_out (Activation) │ (None, 8, 8, 1024)
│
0 │ conv4_block2_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_1_conv (Conv2D) │ (None, 8, 8, 256)
│
262,400 │ conv4_block2_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_1_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block3_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_1_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block3_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_2_conv (Conv2D) │ (None, 8, 8, 256)
│
590,080 │ conv4_block3_1_relu[0][0] │

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_2_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block3_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_2_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block3_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_3_conv (Conv2D) │ (None, 8, 8, 1024)
│
263,168 │ conv4_block3_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_3_bn
│ (None, 8, 8, 1024)
│
4,096 │ conv4_block3_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_add (Add)
│ (None, 8, 8, 1024)
│
0 │ conv4_block2_out[0][0],
│
│
│
│
│ conv4_block3_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block3_out (Activation) │ (None, 8, 8, 1024)
│
0 │ conv4_block3_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block4_1_conv (Conv2D) │ (None, 8, 8, 256)
│
262,400 │ conv4_block3_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block4_1_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block4_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block4_1_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block4_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ conv4_block4_2_conv (Conv2D) │ (None, 8, 8, 256)
│
590,080 │ conv4_block4_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block4_2_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block4_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block4_2_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block4_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block4_3_conv (Conv2D) │ (None, 8, 8, 1024)
│
263,168 │ conv4_block4_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block4_3_bn
│ (None, 8, 8, 1024)
│
4,096 │ conv4_block4_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block4_add (Add)
│ (None, 8, 8, 1024)
│
0 │ conv4_block3_out[0][0],
│
│
│
│
│ conv4_block4_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block4_out (Activation) │ (None, 8, 8, 1024)
│
0 │ conv4_block4_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_1_conv (Conv2D) │ (None, 8, 8, 256)
│
262,400 │ conv4_block4_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_1_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block5_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_1_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block5_1_bn[0][0]
│

│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_2_conv (Conv2D) │ (None, 8, 8, 256)
│
590,080 │ conv4_block5_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_2_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block5_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_2_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block5_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_3_conv (Conv2D) │ (None, 8, 8, 1024)
│
263,168 │ conv4_block5_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_3_bn
│ (None, 8, 8, 1024)
│
4,096 │ conv4_block5_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_add (Add)
│ (None, 8, 8, 1024)
│
0 │ conv4_block4_out[0][0],
│
│
│
│
│ conv4_block5_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block5_out (Activation) │ (None, 8, 8, 1024)
│
0 │ conv4_block5_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block6_1_conv (Conv2D) │ (None, 8, 8, 256)
│
262,400 │ conv4_block5_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block6_1_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block6_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ conv4_block6_1_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block6_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block6_2_conv (Conv2D) │ (None, 8, 8, 256)
│
590,080 │ conv4_block6_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block6_2_bn
│ (None, 8, 8, 256)
│
1,024 │ conv4_block6_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block6_2_relu
│ (None, 8, 8, 256)
│
0 │ conv4_block6_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block6_3_conv (Conv2D) │ (None, 8, 8, 1024)
│
263,168 │ conv4_block6_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block6_3_bn
│ (None, 8, 8, 1024)
│
4,096 │ conv4_block6_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block6_add (Add)
│ (None, 8, 8, 1024)
│
0 │ conv4_block5_out[0][0],
│
│
│
│
│ conv4_block6_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv4_block6_out (Activation) │ (None, 8, 8, 1024)
│
0 │ conv4_block6_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_1_conv (Conv2D) │ (None, 4, 4, 512)
│
524,800 │ conv4_block6_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_1_bn
│ (None, 4, 4, 512)
│
2,048 │ conv5_block1_1_conv[0][0] │

│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_1_relu
│ (None, 4, 4, 512)
│
0 │ conv5_block1_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_2_conv (Conv2D) │ (None, 4, 4, 512)
│
2,359,808 │ conv5_block1_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_2_bn
│ (None, 4, 4, 512)
│
2,048 │ conv5_block1_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_2_relu
│ (None, 4, 4, 512)
│
0 │ conv5_block1_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_0_conv (Conv2D) │ (None, 4, 4, 2048)
│
2,099,200 │ conv4_block6_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_3_conv (Conv2D) │ (None, 4, 4, 2048)
│
1,050,624 │ conv5_block1_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_0_bn
│ (None, 4, 4, 2048)
│
8,192 │ conv5_block1_0_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_3_bn
│ (None, 4, 4, 2048)
│
8,192 │ conv5_block1_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_add (Add)
│ (None, 4, 4, 2048)
│
0 │ conv5_block1_0_bn[0][0],
│
│
│
│

│ conv5_block1_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block1_out (Activation) │ (None, 4, 4, 2048)
│
0 │ conv5_block1_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block2_1_conv (Conv2D) │ (None, 4, 4, 512)
│
1,049,088 │ conv5_block1_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block2_1_bn
│ (None, 4, 4, 512)
│
2,048 │ conv5_block2_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block2_1_relu
│ (None, 4, 4, 512)
│
0 │ conv5_block2_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block2_2_conv (Conv2D) │ (None, 4, 4, 512)
│
2,359,808 │ conv5_block2_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block2_2_bn
│ (None, 4, 4, 512)
│
2,048 │ conv5_block2_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block2_2_relu
│ (None, 4, 4, 512)
│
0 │ conv5_block2_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block2_3_conv (Conv2D) │ (None, 4, 4, 2048)
│
1,050,624 │ conv5_block2_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block2_3_bn
│ (None, 4, 4, 2048)
│
8,192 │ conv5_block2_3_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ conv5_block2_add (Add)
│ (None, 4, 4, 2048)
│
0 │ conv5_block1_out[0][0],
│
│
│
│
│ conv5_block2_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block2_out (Activation) │ (None, 4, 4, 2048)
│
0 │ conv5_block2_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_1_conv (Conv2D) │ (None, 4, 4, 512)
│
1,049,088 │ conv5_block2_out[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_1_bn
│ (None, 4, 4, 512)
│
2,048 │ conv5_block3_1_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_1_relu
│ (None, 4, 4, 512)
│
0 │ conv5_block3_1_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_2_conv (Conv2D) │ (None, 4, 4, 512)
│
2,359,808 │ conv5_block3_1_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_2_bn
│ (None, 4, 4, 512)
│
2,048 │ conv5_block3_2_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_2_relu
│ (None, 4, 4, 512)
│
0 │ conv5_block3_2_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_3_conv (Conv2D) │ (None, 4, 4, 2048)
│
1,050,624 │ conv5_block3_2_relu[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_3_bn
│ (None, 4, 4, 2048)
│
8,192 │ conv5_block3_3_conv[0][0] │
│ (BatchNormalization)
│
│

│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_add (Add)
│ (None, 4, 4, 2048)
│
0 │ conv5_block2_out[0][0],
│
│
│
│
│ conv5_block3_3_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv5_block3_out (Activation) │ (None, 4, 4, 2048)
│
0 │ conv5_block3_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ global_average_pooling2d
│ (None, 2048)
│
0 │ conv5_block3_out[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense (Dense)
│ (None, 1024)
│
2,098,176 │ global_average_pooling2d[… │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_1 (Dense)
│ (None, 1)
│
1,025 │ dense[0][0]
│
└───────────────────────────────┴───────────────────────────┴─────────
────────┴────────────────────────────┘
Total params: 25,686,913 (97.99 MB)
Trainable params: 2,099,201 (8.01 MB)
Non-trainable params: 23,587,712 (89.98 MB)
## 3. Train the Model
## Model Training
## Unfreezing More Layers for Fine-Tuning
# Unfreeze the last 50 layers of ResNet50 for fine-tuning
for layer in base_model.layers[-50:]:
layer.trainable = True
# Compile the model with a lower learning rate for fine-tuning
model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
loss='binary_crossentropy', metrics=['accuracy'])
# Continue training the model
history = model.fit(X_train, y_train, epochs=20, batch_size=32,
validation_split=0.2)

Epoch 1/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 149s 4s/step - accuracy: 0.5124 - loss:
0.7125 - val_accuracy: 0.5600 - val_loss: 0.6901
Epoch 2/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 116s 4s/step - accuracy: 0.6523 - loss:
0.6468 - val_accuracy: 0.5600 - val_loss: 0.6980
Epoch 3/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 188s 6s/step - accuracy: 0.6763 - loss:
0.6204 - val_accuracy: 0.5600 - val_loss: 0.6959
Epoch 4/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 113s 4s/step - accuracy: 0.7063 - loss:
0.5724 - val_accuracy: 0.5600 - val_loss: 0.6954
Epoch 5/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 111s 4s/step - accuracy: 0.7402 - loss:
0.5396 - val_accuracy: 0.5600 - val_loss: 0.6872
Epoch 6/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 112s 4s/step - accuracy: 0.7372 - loss:
0.5220 - val_accuracy: 0.5600 - val_loss: 0.6848
Epoch 7/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 136s 4s/step - accuracy: 0.7800 - loss:
0.4547 - val_accuracy: 0.5600 - val_loss: 0.6825
Epoch 8/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 109s 4s/step - accuracy: 0.7579 - loss:
0.4480 - val_accuracy: 0.5511 - val_loss: 0.6876
Epoch 9/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 114s 4s/step - accuracy: 0.7433 - loss:
0.4511 - val_accuracy: 0.5289 - val_loss: 0.6924
Epoch 10/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 106s 4s/step - accuracy: 0.7596 - loss:
0.4475 - val_accuracy: 0.5467 - val_loss: 0.7056
Epoch 11/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 106s 4s/step - accuracy: 0.7557 - loss:
0.4201 - val_accuracy: 0.4756 - val_loss: 0.7248
Epoch 12/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 106s 4s/step - accuracy: 0.7805 - loss:
0.4376 - val_accuracy: 0.4489 - val_loss: 1.1224
Epoch 13/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 105s 4s/step - accuracy: 0.7904 - loss:
0.3968 - val_accuracy: 0.4578 - val_loss: 0.8223
Epoch 14/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 108s 4s/step - accuracy: 0.7605 - loss:
0.3952 - val_accuracy: 0.4844 - val_loss: 0.8848
Epoch 15/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 109s 4s/step - accuracy: 0.8167 - loss:
0.3606 - val_accuracy: 0.5733 - val_loss: 0.8239
Epoch 16/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 114s 4s/step - accuracy: 0.7957 - loss:
0.3851 - val_accuracy: 0.5511 - val_loss: 0.8756
Epoch 17/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 134s 4s/step - accuracy: 0.7972 - loss:

0.3674 - val_accuracy: 0.5556 - val_loss: 0.9248
Epoch 18/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 111s 4s/step - accuracy: 0.8104 - loss:
0.3548 - val_accuracy: 0.4356 - val_loss: 1.5359
Epoch 19/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 114s 4s/step - accuracy: 0.7995 - loss:
0.3868 - val_accuracy: 0.5200 - val_loss: 0.9772
Epoch 20/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 114s 4s/step - accuracy: 0.7808 - loss:
0.4000 - val_accuracy: 0.5422 - val_loss: 1.2444
## 4. Evaluate the Model using Accuracy, Precision, Recall, F1 Score
## Model Evaluation
from sklearn.metrics import accuracy_score, precision_score,
recall_score, f1_score
# Make predictions on the test set
y_pred = (model.predict(X_test) > 0.5).astype("int32")
# Calculate accuracy, precision, recall, and F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")
9/9 ━━━━━━━━━━━━━━━━━━━━ 16s 2s/step
Accuracy: 0.55
Precision: 0.55
Recall: 0.97
F1 Score: 0.70
## B. Model Setup with MobileNetV2
from tensorflow.keras.applications import MobileNetV2
# Load MobileNetV2
base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False,
weights='imagenet')
# Add classification layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)

# Create and compile the model
model = Model(inputs=base_model.input, outputs=predictions)
model.compile(optimizer='adam', loss='binary_crossentropy',
metrics=['accuracy'])
# Train the model
history = model.fit(X_train, y_train, epochs=20, batch_size=32,
validation_split=0.2, class_weight=class_weights_dict)
Epoch 1/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 92s 2s/step - accuracy: 0.5036 - loss:
1.0903 - val_accuracy: 0.4400 - val_loss: 0.8959
Epoch 2/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 48s 2s/step - accuracy: 0.5518 - loss:
0.6979 - val_accuracy: 0.5600 - val_loss: 0.6932
Epoch 3/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 49s 2s/step - accuracy: 0.5941 - loss:
0.6500 - val_accuracy: 0.5111 - val_loss: 0.6965
Epoch 4/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 49s 2s/step - accuracy: 0.6606 - loss:
0.5865 - val_accuracy: 0.4533 - val_loss: 0.7809
Epoch 5/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 48s 2s/step - accuracy: 0.7083 - loss:
0.5445 - val_accuracy: 0.4311 - val_loss: 0.7153
Epoch 6/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 50s 2s/step - accuracy: 0.6882 - loss:
0.5754 - val_accuracy: 0.4622 - val_loss: 0.7849
Epoch 7/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 48s 2s/step - accuracy: 0.7336 - loss:
0.4910 - val_accuracy: 0.4400 - val_loss: 0.9462
Epoch 8/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 48s 2s/step - accuracy: 0.7150 - loss:
0.5352 - val_accuracy: 0.4400 - val_loss: 2.1997
Epoch 9/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 48s 2s/step - accuracy: 0.7377 - loss:
0.5051 - val_accuracy: 0.4133 - val_loss: 1.5380
Epoch 10/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 49s 2s/step - accuracy: 0.7887 - loss:
0.3999 - val_accuracy: 0.4400 - val_loss: 4.6021
Epoch 11/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.7769 - loss:
0.4237 - val_accuracy: 0.4400 - val_loss: 6.5580
Epoch 12/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.7927 - loss:
0.3670 - val_accuracy: 0.4400 - val_loss: 5.4276
Epoch 13/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 49s 2s/step - accuracy: 0.8240 - loss:
0.3477 - val_accuracy: 0.4400 - val_loss: 7.1789
Epoch 14/20

28/28 ━━━━━━━━━━━━━━━━━━━━ 48s 2s/step - accuracy: 0.8244 - loss:
0.3729 - val_accuracy: 0.4400 - val_loss: 5.6819
Epoch 15/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 49s 2s/step - accuracy: 0.8716 - loss:
0.3018 - val_accuracy: 0.4400 - val_loss: 9.1910
Epoch 16/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 48s 2s/step - accuracy: 0.8561 - loss:
0.3263 - val_accuracy: 0.4400 - val_loss: 9.2010
Epoch 17/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 49s 2s/step - accuracy: 0.8776 - loss:
0.2554 - val_accuracy: 0.4400 - val_loss: 11.5812
Epoch 18/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 49s 2s/step - accuracy: 0.8785 - loss:
0.2357 - val_accuracy: 0.4489 - val_loss: 7.5488
Epoch 19/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 50s 2s/step - accuracy: 0.8755 - loss:
0.3043 - val_accuracy: 0.4400 - val_loss: 5.6919
Epoch 20/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 48s 2s/step - accuracy: 0.9063 - loss:
0.2406 - val_accuracy: 0.4400 - val_loss: 8.6113
# Use a smaller learning rate for fine-tuning
model.compile(optimizer=tf.keras.optimizers.Adam(1e-6),
loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=20, batch_size=32,
validation_split=0.2, class_weight=class_weights)
Epoch 1/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 64s 1s/step - accuracy: 0.8663 - loss:
0.6074 - val_accuracy: 0.5600 - val_loss: 3.2973
Epoch 2/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.8339 - loss:
0.5493 - val_accuracy: 0.5600 - val_loss: 3.2915
Epoch 3/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.8724 - loss:
0.5180 - val_accuracy: 0.5600 - val_loss: 3.2864
Epoch 4/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.8430 - loss:
0.5453 - val_accuracy: 0.5600 - val_loss: 3.2762
Epoch 5/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 37s 1s/step - accuracy: 0.8691 - loss:
0.5533 - val_accuracy: 0.5600 - val_loss: 3.2888
Epoch 6/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.8486 - loss:
0.4900 - val_accuracy: 0.5600 - val_loss: 3.2580
Epoch 7/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 38s 1s/step - accuracy: 0.8753 - loss:
0.4570 - val_accuracy: 0.5600 - val_loss: 3.2570
Epoch 8/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.8653 - loss:

0.4196 - val_accuracy: 0.5644 - val_loss: 3.2321
Epoch 9/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.8881 - loss:
0.4202 - val_accuracy: 0.5600 - val_loss: 3.1844
Epoch 10/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.8733 - loss:
0.4001 - val_accuracy: 0.5644 - val_loss: 3.1286
Epoch 11/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.8636 - loss:
0.4146 - val_accuracy: 0.5644 - val_loss: 3.0753
Epoch 12/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 32s 1s/step - accuracy: 0.8868 - loss:
0.4127 - val_accuracy: 0.5556 - val_loss: 3.0045
Epoch 13/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.8733 - loss:
0.4504 - val_accuracy: 0.5556 - val_loss: 2.9518
Epoch 14/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.8742 - loss:
0.4141 - val_accuracy: 0.5600 - val_loss: 2.8953
Epoch 15/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.8808 - loss:
0.4112 - val_accuracy: 0.5600 - val_loss: 2.8580
Epoch 16/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.8906 - loss:
0.4101 - val_accuracy: 0.5600 - val_loss: 2.8295
Epoch 17/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.8802 - loss:
0.3869 - val_accuracy: 0.5600 - val_loss: 2.8192
Epoch 18/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.8859 - loss:
0.4739 - val_accuracy: 0.5422 - val_loss: 2.8406
Epoch 19/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.9151 - loss:
0.3324 - val_accuracy: 0.5333 - val_loss: 2.8761
Epoch 20/20
28/28 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.8820 - loss:
0.3928 - val_accuracy: 0.5333 - val_loss: 2.9299
## Model Evaluation
from sklearn.metrics import accuracy_score, precision_score,
recall_score, f1_score
# Make predictions on the test set
y_pred = (model.predict(X_test) > 0.5).astype("int32")
# Calculate accuracy, precision, recall, and F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

f1 = f1_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")
9/9 ━━━━━━━━━━━━━━━━━━━━ 5s 447ms/step
Accuracy: 0.56
Precision: 0.56
Recall: 0.93
F1 Score: 0.70
## 5. Visualization
##

A. Precision-Recall Curve

from sklearn.metrics import precision_recall_curve
# Get predicted probabilities
y_probs = model.predict(X_test).ravel()
# Compute precision-recall pairs
precision, recall, thresholds = precision_recall_curve(y_test,
y_probs)
# Plot precision-recall curve
plt.figure()
plt.plot(recall, precision, marker='.', label='Precision-Recall
Curve')
plt.title('Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.grid(True)
plt.show()
9/9 ━━━━━━━━━━━━━━━━━━━━ 3s 281ms/step

##

B. Loss and Accuracy Curves

# Plot training & validation accuracy values
plt.figure()
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.grid(True)
plt.show()
# Plot training & validation loss values
plt.figure()
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.grid(True)
plt.show()

##

C. Bounding Box Visualization

def draw_bounding_box(image, bbox):
x_min, y_min, x_max, y_max = bbox
cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0),
2)
return image
# Sample bounding box (dummy coordinates)
sample_image = X_test[0]
bbox = [30, 30, 90, 90] # Replace with actual bounding box
coordinates
# Draw the bounding box on the sample image
image_with_box = draw_bounding_box(sample_image.copy(), bbox)
plt.imshow(image_with_box)
plt.title('Sample Image with Bounding Box')
plt.show()
Clipping input data to the valid range for imshow with RGB data
([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].

##

D. Box Plot of Metrics

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
# Create a DataFrame for metrics (based on your results)
metrics_data = {
'Accuracy': [0.55, 0.56],
'Precision': [0.55, 0.56],
'Recall': [0.97, 0.93],
'F1 Score': [0.70, 0.70]
}
df_metrics = pd.DataFrame(metrics_data)
# Set up a smaller figure size
plt.figure(figsize=(4, 4)) # Adjust size here (width, height)
# Create the box plot
sns.boxplot(data=df_metrics)
# Set title and grid
plt.title('Evaluation Metrics Box Plot', fontsize=12)
plt.grid(True)

# Show the plot
plt.tight_layout()
plt.show()

### Objective-2 - Developing an unimodal Object Detection system for
Autonomous Vehicles with Radar data
## Importing Libraries
import numpy as np
import h5py
import json
import os
import pandas as pd
import matplotlib.pyplot as plt
# For data preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
# For building neural networks
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
# For evaluation
from sklearn.metrics import classification_report, accuracy_score,
precision_score, recall_score, f1_score
## 1. Load & Data Preprocessing
## Data Exploring
# Paths to the dataset directories
data_dir = 'E:/dataset2'
sequence_path = os.path.join(data_dir, 'sequence_02')
import h5py
# Provide the correct path to the HDF5 file
file_path = 'E:/dataset2/sequence_02/radar_data.h5'
# Open the HDF5 file
with h5py.File(file_path, 'r') as file:
# Print all the keys (groups and datasets) in the file
def print_structure(name, obj):
if isinstance(obj, h5py.Dataset):
print(f"Dataset: {name}, shape: {obj.shape}, dtype:
{obj.dtype}")
elif isinstance(obj, h5py.Group):
print(f"Group: {name}")
# Visit each item in the HDF5 file and print its structure
file.visititems(print_structure)

# Get the size of the entire file (i.e., the number of frames in
each dataset)
for key in file.keys():
dataset = file[key]
print(f"Size of dataset '{key}': {dataset.shape}")
Dataset: odometry, shape: (14526,), dtype: [('timestamp', '<i8'),
('x_seq', '<f4'), ('y_seq', '<f4'), ('yaw_seq', '<f4'), ('vx', '<f4'),
('yaw_rate', '<f4')]
Dataset: radar_data, shape: (1029753,), dtype: [('timestamp', '<i8'),
('sensor_id', 'u1'), ('range_sc', '<f4'), ('azimuth_sc', '<f4'),
('rcs', '<f4'), ('vr', '<f4'), ('vr_compensated', '<f4'), ('x_cc',
'<f4'), ('y_cc', '<f4'), ('x_seq', '<f4'), ('y_seq', '<f4'), ('uuid',
'S32'), ('track_id', 'S32'), ('label_id', 'u1')]
Size of dataset 'odometry': (14526,)
Size of dataset 'radar_data': (1029753,)
import json
# Path to the scenes.json file
scenes_file_path = 'E:/dataset2/sequence_02/scenes.json'
# Load the scenes.json file and display its structure
with open(scenes_file_path, 'r') as f:
annotation_data = json.load(f)
# Print the structure of the JSON file (keys and sample content)
print("Structure of the scenes.json file:")
for key in annotation_data.keys():
print(f"{key}: {type(annotation_data[key])}")
# If the value is a list and not empty, print the first item
if isinstance(annotation_data[key], list) and
len(annotation_data[key]) > 0:
print(f"Sample data for {key}: {annotation_data[key][0]}")
# If the value is a dictionary, print the first key-value pair
elif isinstance(annotation_data[key], dict):
first_key = list(annotation_data[key].keys())[0]
print(f"Sample data for {key}: {first_key}:
{annotation_data[key][first_key]}")
else:
print(f"Value for {key}: {annotation_data[key]}")
# Print the size of the annotation data (number of entries)
print(f"Number of top-level entries in the JSON file:
{len(annotation_data)}")
Structure of the scenes.json file:
sequence_name: <class 'str'>

Value for sequence_name: sequence_2
category: <class 'str'>
Value for category: train
first_timestamp: <class 'int'>
Value for first_timestamp: 158195645746
last_timestamp: <class 'int'>
Value for last_timestamp: 158337396943
scenes: <class 'dict'>
Sample data for scenes: 158195645746: {'sensor_id': 2,
'prev_timestamp': None, 'next_timestamp': 158195659779,
'prev_timestamp_same_sensor': None, 'next_timestamp_same_sensor':
158195717630, 'odometry_timestamp': 158195645349, 'odometry_index':
364, 'image_name': '158195603490.jpg', 'radar_indices': [0, 110]}
Number of top-level entries in the JSON file: 5
# Load radar data from the .h5 file
h5_path = 'E:/dataset2/sequence_02/radar_data.h5'

# Your h5 file path

# Open the h5 file and explore its structure
with h5py.File(h5_path, 'r') as f:
radar_data = f['radar_data'][:]
odometry_data = f['odometry'][:]
print(f"Radar data shape: {radar_data.shape}")
print(f"Odometry data shape: {odometry_data.shape}")
# Extract JSON data for annotations
json_path = 'E:/dataset2/sequence_02/scenes.json' # Your JSON file
path
with open(json_path, 'r') as f:
scenes = json.load(f)
print(f"Scenes JSON loaded with {len(scenes['scenes'])} entries")
Radar data shape: (1029753,)
Odometry data shape: (14526,)
Scenes JSON loaded with 7656 entries
## 2. Feature Selection & Label Selection
# Extract features and labels from radar data
features = np.array([radar_data['range_sc'], radar_data['azimuth_sc'],
radar_data['rcs'],
radar_data['vr'], radar_data['vr_compensated'],
radar_data['x_cc'],
radar_data['y_cc']]).T
labels = radar_data['label_id']
# Train-test split
X_train, X_test, y_train, y_test = train_test_split(features, labels,
test_size=0.2, random_state=42)

# Normalize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
## 3. Building a Neural Network Model
from tensorflow.keras import Input
# Define the neural network model
model = Sequential([
Input(shape=(X_train.shape[1],)),
using Input layer

# Explicitly define input shape

Dense(128, activation='relu'),
BatchNormalization(),
Dropout(0.3),
Dense(64, activation='relu'),
BatchNormalization(),
Dropout(0.3),
Dense(32, activation='relu'),
BatchNormalization(),
Dropout(0.3),
Dense(len(np.unique(y_train)), activation='softmax')
layer for classification
])

# Output

# Compile the model
model.compile(optimizer='adam',
loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# Print the model summary
model.summary()
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳
━━━━━━━━━━━━━━━━━┓
┃ Layer (type)
┃ Output Shape
┃
Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇
━━━━━━━━━━━━━━━━━┩
│ dense (Dense)
│ (None, 128)
│
1,024 │
├──────────────────────────────────────┼─────────────────────────────┼
─────────────────┤
│ batch_normalization
│ (None, 128)
│

512 │
│ (BatchNormalization)
│
│
│
├──────────────────────────────────────┼─────────────────────────────┼
─────────────────┤
│ dropout (Dropout)
│ (None, 128)
│
0 │
├──────────────────────────────────────┼─────────────────────────────┼
─────────────────┤
│ dense_1 (Dense)
│ (None, 64)
│
8,256 │
├──────────────────────────────────────┼─────────────────────────────┼
─────────────────┤
│ batch_normalization_1
│ (None, 64)
│
256 │
│ (BatchNormalization)
│
│
│
├──────────────────────────────────────┼─────────────────────────────┼
─────────────────┤
│ dropout_1 (Dropout)
│ (None, 64)
│
0 │
├──────────────────────────────────────┼─────────────────────────────┼
─────────────────┤
│ dense_2 (Dense)
│ (None, 32)
│
2,080 │
├──────────────────────────────────────┼─────────────────────────────┼
─────────────────┤
│ batch_normalization_2
│ (None, 32)
│
128 │
│ (BatchNormalization)
│
│
│
├──────────────────────────────────────┼─────────────────────────────┼
─────────────────┤
│ dropout_2 (Dropout)
│ (None, 32)
│
0 │
├──────────────────────────────────────┼─────────────────────────────┼
─────────────────┤
│ dense_3 (Dense)
│ (None, 9)
│
297 │
└──────────────────────────────────────┴─────────────────────────────┴
─────────────────┘
Total params: 12,553 (49.04 KB)
Trainable params: 12,105 (47.29 KB)
Non-trainable params: 448 (1.75 KB)
## 4. Training the Model

# Check the unique classes in the labels
num_classes = len(np.unique(y_train))
print(f"Number of unique classes in y_train: {num_classes}")
Number of unique classes in y_train: 9
# Check for invalid label values
invalid_labels = np.unique([label for label in y_train if label >=
num_classes])
print(f"Invalid labels in y_train: {invalid_labels}")
Invalid labels in y_train: [11]
# Re-encode the labels to be between 0 and 1 (if necessary)
y_train = np.where(y_train > 1, 1, y_train) # Force any invalid
labels into the range of 0-1
y_test = np.where(y_test > 1, 1, y_test)
# Apply the same
transformation to the test set
# Check the distribution of labels after re-encoding (if applied)
print("Unique labels in y_train:", np.unique(y_train))
Unique labels in y_train: [0 1]
# Check the count of each label in y_train
unique, counts = np.unique(y_train, return_counts=True)
label_counts = dict(zip(unique, counts))
print("Label distribution in y_train:", label_counts)
Label distribution in y_train: {0: 28858, 1: 794944}
# Train the model
history = model.fit(X_train, y_train, epochs=20, batch_size=32,
validation_split=0.2)
Epoch 1/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 54s 2ms/step - accuracy: 0.9386 loss: 0.2057 - val_accuracy: 0.9842 - val_loss: 0.0410
Epoch 2/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 54s 3ms/step - accuracy: 0.9804 loss: 0.0536 - val_accuracy: 0.9857 - val_loss: 0.0364
Epoch 3/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 86s 3ms/step - accuracy: 0.9825 loss: 0.0490 - val_accuracy: 0.9865 - val_loss: 0.0345
Epoch 4/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 82s 3ms/step - accuracy: 0.9829 loss: 0.0472 - val_accuracy: 0.9876 - val_loss: 0.0328
Epoch 5/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 58s 3ms/step - accuracy: 0.9839 loss: 0.0450 - val_accuracy: 0.9881 - val_loss: 0.0316
Epoch 6/20

20596/20596 ━━━━━━━━━━━━━━━━━━━━ 83s 3ms/step - accuracy: 0.9843 loss: 0.0436 - val_accuracy: 0.9879 - val_loss: 0.0325
Epoch 7/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 53s 3ms/step - accuracy: 0.9843 loss: 0.0433 - val_accuracy: 0.9877 - val_loss: 0.0324
Epoch 8/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 56s 3ms/step - accuracy: 0.9849 loss: 0.0424 - val_accuracy: 0.9885 - val_loss: 0.0305
Epoch 9/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 54s 3ms/step - accuracy: 0.9848 loss: 0.0418 - val_accuracy: 0.9871 - val_loss: 0.0324
Epoch 10/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 58s 3ms/step - accuracy: 0.9847 loss: 0.0419 - val_accuracy: 0.9884 - val_loss: 0.0300
Epoch 11/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 55s 3ms/step - accuracy: 0.9854 loss: 0.0409 - val_accuracy: 0.9886 - val_loss: 0.0312
Epoch 12/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 53s 3ms/step - accuracy: 0.9854 loss: 0.0410 - val_accuracy: 0.9881 - val_loss: 0.0324
Epoch 13/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 87s 3ms/step - accuracy: 0.9855 loss: 0.0401 - val_accuracy: 0.9889 - val_loss: 0.0300
Epoch 14/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 53s 3ms/step - accuracy: 0.9857 loss: 0.0397 - val_accuracy: 0.9890 - val_loss: 0.0294
Epoch 15/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 54s 3ms/step - accuracy: 0.9856 loss: 0.0401 - val_accuracy: 0.9895 - val_loss: 0.0285
Epoch 16/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 57s 3ms/step - accuracy: 0.9854 loss: 0.0400 - val_accuracy: 0.9884 - val_loss: 0.0319
Epoch 17/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 54s 3ms/step - accuracy: 0.9857 loss: 0.0397 - val_accuracy: 0.9893 - val_loss: 0.0290
Epoch 18/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 58s 3ms/step - accuracy: 0.9858 loss: 0.0396 - val_accuracy: 0.9880 - val_loss: 0.0318
Epoch 19/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 54s 3ms/step - accuracy: 0.9860 loss: 0.0386 - val_accuracy: 0.9893 - val_loss: 0.0285
Epoch 20/20
20596/20596 ━━━━━━━━━━━━━━━━━━━━ 57s 3ms/step - accuracy: 0.9861 loss: 0.0391 - val_accuracy: 0.9878 - val_loss: 0.0320
## 5. Evaluating the Model
from sklearn.metrics import accuracy_score, precision_score,
recall_score, f1_score

# Make predictions
y_pred = model.predict(X_test)
y_pred = np.argmax(y_pred, axis=1)
classification

# If using softmax for

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
'macro' for multi-class
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')

# Use

# Display the results
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
6436/6436 ━━━━━━━━━━━━━━━━━━━━ 8s 1ms/step
Accuracy: 0.9872
Precision: 0.9586
Recall: 0.8424
F1 Score: 0.8914
## 6. Visualizations
##

A. Loss and Accuracy Curves

# Plotting training & validation accuracy values
plt.figure(figsize=(10, 5))
# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
# Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

##

B. Box Plot of Metrics

import numpy as np
import pandas as pd
# Creating a DataFrame of the metrics
metrics_df = pd.DataFrame({
'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],
'Value': [accuracy, precision, recall, f1]
})
# Box Plot
plt.figure(figsize=(6, 4))
sns.boxplot(x='Metric', y='Value', data=metrics_df)
plt.title('Box Plot of Metrics')
plt.show()

### Objective-3 - Integrating Camera and Radar data for a multi-sensor
object detection system
## Importing Libraries
import os
import json
import h5py
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense,
Flatten, Input, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img,
img_to_array
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score,
recall_score, f1_score
## 1. Load the Data
##

Data Exploring

import os
camera_images_path = 'E:/dataset5/sequence_05/camera' # Update the
path to your actual dataset structure
image_paths = [os.path.join(camera_images_path, img) for img in
os.listdir(camera_images_path)]
# Check if there are valid image files in the directory
if not image_paths:
print("No images found in the specified directory.")
else:
print(f"Found {len(image_paths)} images.")
Found 198 images.
import h5py
# Provide the correct path to the HDF5 file
file_path = 'E:/dataset5/sequence_05/radar_data.h5'
# Open the HDF5 file
with h5py.File(file_path, 'r') as file:
# Print all the keys (groups and datasets) in the file
def print_structure(name, obj):
if isinstance(obj, h5py.Dataset):

print(f"Dataset: {name}, shape: {obj.shape}, dtype:
{obj.dtype}")
elif isinstance(obj, h5py.Group):
print(f"Group: {name}")
# Visit each item in the HDF5 file and print its structure
file.visititems(print_structure)
# Get the size of the entire file (i.e., the number of frames in
each dataset)
for key in file.keys():
dataset = file[key]
print(f"Size of dataset '{key}': {dataset.shape}")
Dataset: odometry, shape: (7891,), dtype: [('timestamp', '<i8'),
('x_seq', '<f4'), ('y_seq', '<f4'), ('yaw_seq', '<f4'), ('vx', '<f4'),
('yaw_rate', '<f4')]
Dataset: radar_data, shape: (366645,), dtype: [('timestamp', '<i8'),
('sensor_id', 'u1'), ('range_sc', '<f4'), ('azimuth_sc', '<f4'),
('rcs', '<f4'), ('vr', '<f4'), ('vr_compensated', '<f4'), ('x_cc',
'<f4'), ('y_cc', '<f4'), ('x_seq', '<f4'), ('y_seq', '<f4'), ('uuid',
'S32'), ('track_id', 'S32'), ('label_id', 'u1')]
Size of dataset 'odometry': (7891,)
Size of dataset 'radar_data': (366645,)
import json
# Path to the scenes.json file
scenes_file_path = 'E:/dataset5/sequence_05/scenes.json'
# Load the scenes.json file and display its structure
with open(scenes_file_path, 'r') as f:
annotation_data = json.load(f)
# Print the structure of the JSON file (keys and sample content)
print("Structure of the scenes.json file:")
for key in annotation_data.keys():
print(f"{key}: {type(annotation_data[key])}")
# If the value is a list and not empty, print the first item
if isinstance(annotation_data[key], list) and
len(annotation_data[key]) > 0:
print(f"Sample data for {key}: {annotation_data[key][0]}")
# If the value is a dictionary, print the first key-value pair
elif isinstance(annotation_data[key], dict):
first_key = list(annotation_data[key].keys())[0]
print(f"Sample data for {key}: {first_key}:
{annotation_data[key][first_key]}")
else:
print(f"Value for {key}: {annotation_data[key]}")

# Print the size of the annotation data (number of entries)
print(f"Number of top-level entries in the JSON file:
{len(annotation_data)}")
Structure of the scenes.json file:
sequence_name: <class 'str'>
Value for sequence_name: sequence_5
category: <class 'str'>
Value for category: validation
first_timestamp: <class 'int'>
Value for first_timestamp: 2078762651025
last_timestamp: <class 'int'>
Value for last_timestamp: 2078838065619
scenes: <class 'dict'>
Sample data for scenes: 2078762651025: {'sensor_id': 1,
'prev_timestamp': None, 'next_timestamp': 2078762653413,
'prev_timestamp_same_sensor': None, 'next_timestamp_same_sensor':
2078762722682, 'odometry_timestamp': 2078762648221, 'odometry_index':
365, 'image_name': '2078762604144.jpg', 'radar_indices': [0, 94]}
Number of top-level entries in the JSON file: 5
h5_path = 'E:/dataset5/sequence_05/radar_data.h5'

# Your h5 file path

# Open the h5 file and explore its structure
with h5py.File(h5_path, 'r') as f:
radar_data = f['radar_data'][:]
odometry_data = f['odometry'][:]
print(f"Radar data shape: {radar_data.shape}")
print(f"Odometry data shape: {odometry_data.shape}")
# Extract JSON data for annotations
json_path = 'E:/dataset5/sequence_05/scenes.json' # Your JSON file
path
with open(json_path, 'r') as f:
scenes = json.load(f)
print(f"Scenes JSON loaded with {len(scenes['scenes'])} entries")
Radar data shape: (366645,)
Odometry data shape: (7891,)
Scenes JSON loaded with 4058 entries
## Load Camera Data
import os
from PIL import Image
import matplotlib.pyplot as plt
# 1. Define the path to the camera images folder
camera_folder_path = 'E:/dataset5/sequence_05/camera'

# 2. List all image files in the camera folder
def list_camera_images(folder_path):
supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')
image_files = [f for f in os.listdir(folder_path) if
f.lower().endswith(supported_formats)]
return sorted(image_files) # Sorting can help in synchronization
camera_images = list_camera_images(camera_folder_path)
# 3. Inspect the list of camera images
print(f"Total Camera Images: {len(camera_images)}")
print("First 5 Camera Images:")
print(camera_images[:5])
# 4. Function to load a sample image
def load_camera_image(image_name, folder_path):
image_path = os.path.join(folder_path, image_name)
image = Image.open(image_path)
return image
# Load and display the first camera image
sample_image_name = camera_images[0]
sample_image = load_camera_image(sample_image_name,
camera_folder_path)
print(f"Loaded Image: {sample_image_name}, Size: {sample_image.size},
Mode: {sample_image.mode}")
# Display the image
plt.imshow(sample_image)
plt.title(f"Sample Image: {sample_image_name}")
plt.axis('off')
plt.show()
Total Camera Images: 198
First 5 Camera Images:
['2078759004099.jpg', '2078759403856.jpg', '2078759804109.jpg',
'2078760204121.jpg', '2078760604124.jpg']
Loaded Image: 2078759004099.jpg, Size: (1067, 480), Mode: RGB

camera_images = list_camera_images(camera_folder_path)
print("Camera images loaded successfully.")
Camera images loaded successfully.
## Load Radar Data
import os
import h5py
import numpy as np
# 1. Define the path to the radar_data.h5 file
radar_data_path = 'E:/dataset5/sequence_05/radar_data.h5'
# 2. Function to load radar data
def load_radar_data(h5_file_path):
with h5py.File(h5_file_path, 'r') as f:
radar_data = f['radar_data'][:] # Load all radar data
return radar_data
# 3. Load the radar data
radar_data = load_radar_data(radar_data_path)
# 4. Inspect the radar data
print("Radar Data Type:", radar_data.dtype)
print("Radar Data Shape:", radar_data.shape)
print("First 5 Radar Entries:")
print(radar_data[:5])
Radar Data Type: [('timestamp', '<i8'), ('sensor_id', 'u1'),
('range_sc', '<f4'), ('azimuth_sc', '<f4'), ('rcs', '<f4'), ('vr',
'<f4'), ('vr_compensated', '<f4'), ('x_cc', '<f4'), ('y_cc', '<f4'),
('x_seq', '<f4'), ('y_seq', '<f4'), ('uuid', 'S32'), ('track_id',
'S32'), ('label_id', 'u1')]
Radar Data Shape: (366645,)

First 5 Radar Entries:
[(2078762651025, 1, 15.204274, -0.94941014, -8.967562, 0.01344358,
0.01344358, -7.88717 , -10.760544, 23.246782, -63.65324,
b'e772c40377bcac93a657d503dd95e100', b'', 11)
(2078762651025, 1, 8.291416, -0.92723584, -8.756395, -0.20475078, 0.20475078, -2.514604 , -6.403352, 29.674902, -66.2084 ,
b'0411b6ec2e9fa95f004c12c048db8997', b'', 11)
(2078762651025, 1, 10.212634, -0.31854045, -23.922726, -0.00255237, 0.00255237, 1.3155655, -10.812187, 27.70259 , -71.70549,
b'bfdb1525458e6cdbfc727030abaec47f', b'', 11)
(2078762651025, 1, 10.412143, 0.49046072, -20.036438, 0.00236196,
0.00236196, 9.343574 , -9.599041, 32.68707 , -78.11452,
b'a4d7e893e9cd1fb4f40eff0cbda6ef48', b'', 11)
(2078762651025, 1, 16.565825, 0.3856975 , -11.150873, -0.00102517, 0.00102517, 11.199508 , -15.625207, 28.338501, -82.6806 ,
b'24215e9a84dae0cddf98d9c32da262cb', b'', 11)]
radar_data = load_radar_data(radar_data_path)
print("Radar data loaded successfully.")
Radar data loaded successfully.
## Load Annotations
import os
import json
# 1. Define the path to the scenes.json file
scenes_json_path = 'E:/dataset5/sequence_05/scenes.json'
# 2. Function to load scenes.json
def load_scenes(json_file_path):
with open(json_file_path, 'r') as file:
scenes = json.load(file)
return scenes
# 3. Load the scenes data
scenes_data = load_scenes(scenes_json_path)
scenes_data = load_scenes(scenes_json_path)
print("Annotations loaded successfully.")
Annotations loaded successfully.
## 2. Preprocess the Data
##

Preprocessing Camera Images

from tensorflow.keras.preprocessing.image import img_to_array,
load_img
from tensorflow.keras.applications.vgg16 import preprocess_input

# Preprocess camera images (resize and normalize)
def preprocess_camera_image(image_path, target_size=(224, 224)):
# Resize and convert to array
img = load_img(image_path, target_size=target_size)
img_array = img_to_array(img)
# Normalize for the CNN model (e.g., VGG16 expects mean-centered
pixel values)
img_array = preprocess_input(img_array)
return img_array
##

Preprocessing Radar Data

import numpy as np
from sklearn.preprocessing import MinMaxScaler
# Preprocess radar data (select and normalize all available features)
def preprocess_radar_data_all_features(radar_data, radar_indices):
# Select all numeric features (excluding uuid, track_id, and
label_id)
selected_radar_data = radar_data[radar_indices]
# Stack all the relevant numeric features
radar_features = np.array([
selected_radar_data['timestamp'],
selected_radar_data['sensor_id'],
selected_radar_data['range_sc'],
selected_radar_data['azimuth_sc'],
selected_radar_data['rcs'],
selected_radar_data['vr'],
selected_radar_data['vr_compensated'],
selected_radar_data['x_cc'],
selected_radar_data['y_cc'],
selected_radar_data['x_seq'],
selected_radar_data['y_seq']
]).T # Transpose to align features as columns
# Normalize the features using MinMaxScaler
scaler = MinMaxScaler()
normalized_radar_features = scaler.fit_transform(radar_features)
return normalized_radar_features
##

Preprocessing Example Usage

# Example: Preprocess a single camera image
camera_image_path = 'E:/dataset5/sequence_05/camera/2078759004099.jpg'
# Replace with actual image path

preprocessed_camera_image = preprocess_camera_image(camera_image_path)
# Print the shape of the preprocessed camera features
print(f"Preprocessed Camera Image Shape:
{preprocessed_camera_image.shape}")
# Example: Preprocess radar data for a specific set of radar indices
# Assume radar_data is already loaded, and radar_indices are available
radar_indices = [0, 89] # Replace with actual radar indices
preprocessed_radar_features =
preprocess_radar_data_all_features(radar_data, radar_indices)
# Print the shape of the preprocessed radar features
print(f"Preprocessed Radar Features Shape:
{preprocessed_radar_features.shape}")
Preprocessed Camera Image Shape: (224, 224, 3)
Preprocessed Radar Features Shape: (2, 11)
## 3. Synchronization of Camera & Radar Data
# Synchronize and preprocess camera and radar data
def synchronize_data(camera_folder, scenes_dict, radar_data):
# Access the 'scenes' key from the main dictionary
scenes = scenes_dict['scenes']
# Get the total number of radar data entries
max_radar_index = radar_data.shape[0]
synchronized_pairs = []
for timestamp, scene_info in scenes.items():
# Get the camera image name and radar indices from the scene
image_name = scene_info.get('image_name')
radar_indices = scene_info.get('radar_indices', [])
# Ensure both camera image and radar data are available
if image_name and radar_indices:
# Preprocess the camera image
image_path = os.path.join(camera_folder, image_name)
preprocessed_camera_image =
preprocess_camera_image(image_path)
# Filter radar indices that are within bounds
valid_radar_indices = [idx for idx in radar_indices if idx
< max_radar_index]
# Only preprocess radar data if valid indices exist
if valid_radar_indices:
preprocessed_radar_features =

preprocess_radar_data_all_features(radar_data, valid_radar_indices)
# Store the synchronized pair (camera image and radar
features)

synchronized_pairs.append((preprocessed_camera_image,
preprocessed_radar_features))
return synchronized_pairs
# Synchronize and preprocess camera and radar data
synchronized_data = synchronize_data(camera_folder_path, scenes,
radar_data)
# Example: Inspect the first synchronized pair (camera image and radar
features)
print(f"Camera Image Shape: {synchronized_data[0][0].shape}")
print(f"Radar Features Shape: {synchronized_data[0][1].shape}")
Camera Image Shape: (224, 224, 3)
Radar Features Shape: (2, 11)
## 4. Feature Extraction
## Camera Images
import tensorflow as tf # Import TensorFlow for Keras layers from
TensorFlow
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
# Load the pre-trained VGG16 model + higher level layers
def create_camera_feature_extractor():
vgg_model = VGG16(weights='imagenet', include_top=False,
input_shape=(224, 224, 3))
# Freeze the pre-trained layers (if you want to fine-tune later,
you can unfreeze these)
for layer in vgg_model.layers:
layer.trainable = False
# Add a global spatial average pooling layer to reduce dimensions
model_output = vgg_model.output
model_output = tf.keras.layers.GlobalAveragePooling2D()
(model_output)
# Create a model that will output features
feature_extractor = Model(inputs=vgg_model.input,
outputs=model_output)
return feature_extractor

# Create the feature extractor for camera images
camera_feature_extractor = create_camera_feature_extractor()
# Example: Extract features for the first preprocessed camera image
camera_features =
camera_feature_extractor.predict(np.expand_dims(synchronized_data[0]
[0], axis=0)) # Add batch dimension
print(f"Extracted Camera Features Shape: {camera_features.shape}")
1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step
Extracted Camera Features Shape: (1, 512)
## Radar Data
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.models import Model
# Create radar feature extractor
def create_radar_feature_extractor(input_shape=(11,)):
radar_input = Input(shape=input_shape, name='radar_input')
x = Dense(64, activation='relu')(radar_input)
x = Dense(128, activation='relu')(x)
x = Dense(128, activation='relu')(x)
radar_feature_extractor = Model(inputs=radar_input, outputs=x)
return radar_feature_extractor
# Create the feature extractor for radar data
radar_feature_extractor = create_radar_feature_extractor()
# Example: Extract features for the first preprocessed radar data
radar_features = radar_feature_extractor.predict(synchronized_data[0]
[1])
print(f"Extracted Radar Features Shape: {radar_features.shape}")
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 111ms/step
Extracted Radar Features Shape: (2, 128)
## Preparing padded radar data
import numpy as np
# Define the maximum length for radar data (you can adjust this value)
max_len = 100 # Truncate or pad radar features to this length
# Function to pad or truncate radar data
def pad_or_truncate_radar_features(radar_features, max_len):
# Check if radar_features is valid and has a 2D shape
if not hasattr(radar_features, 'shape') or

len(radar_features.shape) != 2:
# Handle invalid or empty radar data
return np.zeros((max_len, 11)) # Return padded zeros if the
shape is incorrect
# Get the current number of radar points for this sample
current_len = radar_features.shape[0]
if current_len > max_len:
# Truncate radar data if it exceeds max_len
radar_features = radar_features[:max_len, :]
elif current_len < max_len:
# Pad radar data with zeros if it's shorter than max_len
padding = np.zeros((max_len - current_len,
radar_features.shape[1]))
radar_features = np.vstack((radar_features, padding))
return radar_features
# Prepare padded radar data
padded_radar_data = []
# Iterate through each radar sample and apply padding or truncation
for radar_features in radar_data:
# Handle invalid entries and apply padding/truncation
padded_radar_features =
pad_or_truncate_radar_features(radar_features, max_len)
padded_radar_data.append(padded_radar_features)
# Convert the padded radar data to a NumPy array
padded_radar_data = np.array(padded_radar_data)
# Check the shape of the padded radar data
print(f"Padded Radar Data Shape: {padded_radar_data.shape}")
Padded Radar Data Shape: (366645, 100, 11)
import numpy as np
# Define the maximum number of radar points per sample
max_len = 100 # Adjust this based on your dataset
# Function to pad or truncate radar data
def pad_or_truncate_radar_data(radar_sample, max_len):
current_len = radar_sample.shape[0]
if current_len > max_len:
# Truncate radar data if it exceeds max_len
return radar_sample[:max_len]
else:

# Pad radar data with zeros if it's shorter than max_len
padding = np.zeros((max_len - current_len,
radar_sample.shape[1]))
return np.vstack((radar_sample, padding))
# Pad or truncate radar data for all samples
padded_radar_data = [pad_or_truncate_radar_data(radar_sample, max_len)
for radar_sample in [pair[1] for pair in synchronized_data]]
# Convert the padded radar data to a NumPy array
padded_radar_data = np.array(padded_radar_data)
# Check the shape of the padded radar data
print(f"Padded Radar Data Shape: {padded_radar_data.shape}")
Padded Radar Data Shape: (4058, 100, 11)
## 5. Model Building
import tensorflow as tf
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense,
Input, Concatenate, GlobalAveragePooling2D
from tensorflow.keras.models import Model
# 1. Camera Branch (CNN - VGG16)
def create_camera_branch(input_shape=(224, 224, 3)):
vgg_model = tf.keras.applications.VGG16(weights='imagenet',
include_top=False, input_shape=input_shape)
# Freeze the layers of the pre-trained model
for layer in vgg_model.layers:
layer.trainable = False
# Add Global Average Pooling to reduce dimensions
camera_output = GlobalAveragePooling2D()(vgg_model.output)
return vgg_model.input, camera_output
# 2. Updated Radar Branch (1D Conv for Padded Radar Data)
def create_radar_branch(input_shape=(100, 11)): # Adjust input shape
based on padded radar data
radar_input = Input(shape=input_shape, name='radar_input')
# 1D Convolutional layers to process radar data
x = Conv1D(64, kernel_size=3, activation='relu')(radar_input)
x = MaxPooling1D(pool_size=2)(x)
x = Conv1D(128, kernel_size=3, activation='relu')(x)
x = MaxPooling1D(pool_size=2)(x)
x = tf.keras.layers.GlobalAveragePooling1D()(x) # Pool to reduce
dimensions

return radar_input, x
# 3. Fusion Model
def create_fusion_model(camera_input_shape=(224, 224, 3),
radar_input_shape=(100, 11)):
# Create Camera Branch
camera_input, camera_output =
create_camera_branch(camera_input_shape)
# Create Radar Branch
radar_input, radar_output = create_radar_branch(radar_input_shape)
# Concatenate camera and radar features (fusion layer)
fused_output = Concatenate()([camera_output, radar_output])
# Fully connected layers after fusion
z = Dense(256, activation='relu')(fused_output)
z = Dense(128, activation='relu')(z)
z = Dense(1, activation='sigmoid')(z) # Output layer (binary
classification)
# Create the model
model = Model(inputs=[camera_input, radar_input], outputs=z)
# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy',
metrics=['accuracy'])
return model
# Create the fusion model
fusion_model = create_fusion_model()
# Summary of the model
fusion_model.summary()
Model: "functional_2"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━
━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)
┃ Output Shape
┃
Param # ┃ Connected to
┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━
━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)
│ (None, 224, 224, 3)
│
0 │ │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1_conv1 (Conv2D)
│ (None, 224, 224, 64)
│

1,792 │ input_layer_1[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1_conv2 (Conv2D)
│ (None, 224, 224, 64)
│
36,928 │ block1_conv1[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1_pool (MaxPooling2D)
│ (None, 112, 112, 64)
│
0 │ block1_conv2[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2_conv1 (Conv2D)
│ (None, 112, 112, 128)
│
73,856 │ block1_pool[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2_conv2 (Conv2D)
│ (None, 112, 112, 128)
│
147,584 │ block2_conv1[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2_pool (MaxPooling2D)
│ (None, 56, 56, 128)
│
0 │ block2_conv2[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3_conv1 (Conv2D)
│ (None, 56, 56, 256)
│
295,168 │ block2_pool[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3_conv2 (Conv2D)
│ (None, 56, 56, 256)
│
590,080 │ block3_conv1[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3_conv3 (Conv2D)
│ (None, 56, 56, 256)
│
590,080 │ block3_conv2[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3_pool (MaxPooling2D)
│ (None, 28, 28, 256)
│
0 │ block3_conv3[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4_conv1 (Conv2D)
│ (None, 28, 28, 512)
│
1,180,160 │ block3_pool[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4_conv2 (Conv2D)
│ (None, 28, 28, 512)
│
2,359,808 │ block4_conv1[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4_conv3 (Conv2D)
│ (None, 28, 28, 512)
│
2,359,808 │ block4_conv2[0][0]
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4_pool (MaxPooling2D)
│ (None, 14, 14, 512)
│
0 │ block4_conv3[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ radar_input (InputLayer)
│ (None, 100, 11)
│
0 │ │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5_conv1 (Conv2D)
│ (None, 14, 14, 512)
│
2,359,808 │ block4_pool[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv1d (Conv1D)
│ (None, 98, 64)
│
2,176 │ radar_input[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5_conv2 (Conv2D)
│ (None, 14, 14, 512)
│
2,359,808 │ block5_conv1[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ max_pooling1d (MaxPooling1D) │ (None, 49, 64)
│
0 │ conv1d[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5_conv3 (Conv2D)
│ (None, 14, 14, 512)
│
2,359,808 │ block5_conv2[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ conv1d_1 (Conv1D)
│ (None, 47, 128)
│
24,704 │ max_pooling1d[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5_pool (MaxPooling2D)
│ (None, 7, 7, 512)
│
0 │ block5_conv3[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ max_pooling1d_1
│ (None, 23, 128)
│
0 │ conv1d_1[0][0]
│
│ (MaxPooling1D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ global_average_pooling2d_1
│ (None, 512)
│
0 │ block5_pool[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ global_average_pooling1d
│ (None, 128)
│
0 │ max_pooling1d_1[0][0]
│
│ (GlobalAveragePooling1D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ concatenate (Concatenate)
│ (None, 640)
│
0 │ global_average_pooling2d_… │
│
│
│
│ global_average_pooling1d[… │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_3 (Dense)
│ (None, 256)
│
164,096 │ concatenate[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_4 (Dense)
│ (None, 128)
│
32,896 │ dense_3[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_5 (Dense)
│ (None, 1)
│
129 │ dense_4[0][0]
│
└───────────────────────────────┴───────────────────────────┴─────────
────────┴────────────────────────────┘
Total params: 14,938,689 (56.99 MB)
Trainable params: 224,001 (875.00 KB)
Non-trainable params: 14,714,688 (56.13 MB)
## 6. Preparing Training & Validation data
# Generate dummy labels (binary classification: 0 or 1)
# The number of labels should match the number of synchronized data
pairs (4058)
labels = np.random.randint(0, 2, size=(len(synchronized_data),))
# Check the shape of labels
print(f"Labels Shape: {labels.shape}")
Labels Shape: (4058,)
from sklearn.model_selection import train_test_split
# Extract camera and radar data from the synchronized pairs
camera_data = np.array([pair[0] for pair in synchronized_data])
# Split the data into training and validation sets
camera_train_data, camera_val_data, radar_train_data, radar_val_data,

train_labels, val_labels = train_test_split(
camera_data, padded_radar_data, labels, test_size=0.2,
random_state=42
)
# Print the shapes of the split data
print(f"Training Camera Data Shape: {camera_train_data.shape}")
print(f"Validation Camera Data Shape: {camera_val_data.shape}")
print(f"Training Radar Data Shape: {radar_train_data.shape}")
print(f"Validation Radar Data Shape: {radar_val_data.shape}")
print(f"Training Labels Shape: {train_labels.shape}")
print(f"Validation Labels Shape: {val_labels.shape}")
Training Camera Data Shape: (3246, 224, 224, 3)
Validation Camera Data Shape: (812, 224, 224, 3)
Training Radar Data Shape: (3246, 100, 11)
Validation Radar Data Shape: (812, 100, 11)
Training Labels Shape: (3246,)
Validation Labels Shape: (812,)
## 7. Training the Model
# Train the fusion model
history = fusion_model.fit(
[camera_train_data, radar_train_data], # Input: camera and radar
training data
train_labels,
# Output: training labels
epochs=10,
batch_size=32,
validation_data=([camera_val_data, radar_val_data], val_labels)
)
Epoch 1/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 2634s 26s/step - accuracy: 0.5082 - loss:
0.9246 - val_accuracy: 0.5049 - val_loss: 0.7081
Epoch 2/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 788s 8s/step - accuracy: 0.4994 - loss:
0.7231 - val_accuracy: 0.5025 - val_loss: 0.6947
Epoch 3/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 858s 8s/step - accuracy: 0.5021 - loss:
0.7064 - val_accuracy: 0.4988 - val_loss: 0.7054
Epoch 4/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 646s 6s/step - accuracy: 0.5142 - loss:
0.7034 - val_accuracy: 0.5135 - val_loss: 0.6932
Epoch 5/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 638s 6s/step - accuracy: 0.5135 - loss:
0.6987 - val_accuracy: 0.5025 - val_loss: 0.7068
Epoch 6/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 640s 6s/step - accuracy: 0.4938 - loss:
0.7039 - val_accuracy: 0.5111 - val_loss: 0.6916

Epoch 7/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 642s 6s/step - accuracy: 0.4904 - loss:
0.6947 - val_accuracy: 0.5160 - val_loss: 0.6940
Epoch 8/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 643s 6s/step - accuracy: 0.5089 - loss:
0.6968 - val_accuracy: 0.5062 - val_loss: 0.6931
Epoch 9/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 645s 6s/step - accuracy: 0.5094 - loss:
0.6957 - val_accuracy: 0.5025 - val_loss: 0.6939
Epoch 10/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 650s 6s/step - accuracy: 0.5199 - loss:
0.6923 - val_accuracy: 0.5025 - val_loss: 0.6989
## 8. Evaluating the Model
# Make predictions on the validation set
y_pred_prob = fusion_model.predict([camera_val_data, radar_val_data])
# Convert predicted probabilities to binary predictions (for binary
classification)
y_pred = (y_pred_prob > 0.5).astype("int32")
26/26 ━━━━━━━━━━━━━━━━━━━━ 104s 4s/step
from sklearn.metrics import accuracy_score, precision_score,
recall_score, f1_score
# Calculate accuracy, precision, recall, and F1 score
accuracy = accuracy_score(val_labels, y_pred)
precision = precision_score(val_labels, y_pred, zero_division=1)
recall = recall_score(val_labels, y_pred, zero_division=1)
f1 = f1_score(val_labels, y_pred, zero_division=1)
# Print the evaluation metrics
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")
Accuracy: 0.50
Precision: 0.50
Recall: 1.00
F1 Score: 0.67
## Using EfficientNet as the CNN for Camera data
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Input, Concatenate

# Camera Branch (EfficientNetB0)
def create_camera_branch(input_shape=(224, 224, 3)):
efficientnet_model = EfficientNetB0(weights='imagenet',
include_top=False, input_shape=input_shape)
# Freeze the EfficientNet layers to prevent updating during
training
for layer in efficientnet_model.layers:
layer.trainable = False
# Add global average pooling
camera_output = GlobalAveragePooling2D()
(efficientnet_model.output)
return efficientnet_model.input, camera_output
# Radar Branch (Fully Connected Layers)
def create_radar_branch(input_shape=(100, 11), output_dim=1280):
radar_input = Input(shape=input_shape, name='radar_input')
# Dense layers to process radar features
x = Dense(256, activation='relu')(radar_input)
x = Dense(128, activation='relu')(x)
# Add a final dense layer to match the camera feature dimension
(1280)
radar_output = Dense(output_dim, activation='relu')(x)
return radar_input, radar_output
## Cross-Attention Fusion Mechanism
from tensorflow.keras.layers import Reshape, MultiHeadAttention,
LayerNormalization
# Cross-attention fusion network
def cross_attention_fusion(camera_features, radar_features):
# Reshape camera features to match radar features (add a sequence
length of 1)
camera_features_reshaped = Reshape((1, camera_features.shape[-1]))
(camera_features)
# Multi-head attention (cross-attention)
attention_output, _ = MultiHeadAttention(num_heads=4, key_dim=128,
value_dim=128, dropout=0.1)(
query=camera_features_reshaped, key=radar_features,
value=radar_features, return_attention_scores=True)
# Add normalization
fused_output = LayerNormalization()(attention_output)

# Optionally reshape the fused output back to 2D
fused_output = Reshape((fused_output.shape[-1],))(fused_output)
return fused_output
## Build the Fusion Model
def create_advanced_fusion_model(camera_input_shape=(224, 224, 3),
radar_input_shape=(100, 11)):
# Camera branch
camera_input, camera_output =
create_camera_branch(camera_input_shape)
# Radar branch
radar_input, radar_output = create_radar_branch(radar_input_shape,
output_dim=camera_output.shape[-1])
# Cross-attention fusion mechanism
fused_output = cross_attention_fusion(camera_output, radar_output)
# Fully connected layers after fusion
x = Dense(256, activation='relu')(fused_output)
x = Dense(128, activation='relu')(x)
output = Dense(1, activation='sigmoid')(x) # Binary
classification
# Build the fusion model
model = Model(inputs=[camera_input, radar_input], outputs=output)
# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy',
metrics=['accuracy'])
return model
# Create the advanced fusion model
advanced_fusion_model = create_advanced_fusion_model()
# Print the model summary
advanced_fusion_model.summary()
Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━
━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)
┃ Output Shape
┃
Param # ┃ Connected to
┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━
━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩

│ input_layer_2 (InputLayer)
│ (None, 224, 224, 3)
│
0 │ │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ rescaling (Rescaling)
│ (None, 224, 224, 3)
│
0 │ input_layer_2[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ normalization (Normalization) │ (None, 224, 224, 3)
│
7 │ rescaling[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ rescaling_1 (Rescaling)
│ (None, 224, 224, 3)
│
0 │ normalization[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ stem_conv_pad (ZeroPadding2D) │ (None, 225, 225, 3)
│
0 │ rescaling_1[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ stem_conv (Conv2D)
│ (None, 112, 112, 32)
│
864 │ stem_conv_pad[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ stem_bn (BatchNormalization) │ (None, 112, 112, 32)
│
128 │ stem_conv[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ stem_activation (Activation) │ (None, 112, 112, 32)
│
0 │ stem_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1a_dwconv
│ (None, 112, 112, 32)
│
288 │ stem_activation[0][0]
│
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1a_bn
│ (None, 112, 112, 32)
│
128 │ block1a_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1a_activation
│ (None, 112, 112, 32)
│
0 │ block1a_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ block1a_se_squeeze
│ (None, 32)
│
0 │ block1a_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1a_se_reshape (Reshape) │ (None, 1, 1, 32)
│
0 │ block1a_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1a_se_reduce (Conv2D)
│ (None, 1, 1, 8)
│
264 │ block1a_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1a_se_expand (Conv2D)
│ (None, 1, 1, 32)
│
288 │ block1a_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1a_se_excite (Multiply) │ (None, 112, 112, 32)
│
0 │ block1a_activation[0][0], │
│
│
│
│ block1a_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1a_project_conv (Conv2D) │ (None, 112, 112, 16)
│
512 │ block1a_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block1a_project_bn
│ (None, 112, 112, 16)
│
64 │ block1a_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_expand_conv (Conv2D) │ (None, 112, 112, 96)
│
1,536 │ block1a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_expand_bn
│ (None, 112, 112, 96)
│
384 │ block2a_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_expand_activation
│ (None, 112, 112, 96)
│
0 │ block2a_expand_bn[0][0]
│
│ (Activation)
│
│
│
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_dwconv_pad
│ (None, 113, 113, 96)
│
0 │ block2a_expand_activation… │
│ (ZeroPadding2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_dwconv
│ (None, 56, 56, 96)
│
864 │ block2a_dwconv_pad[0][0]
│
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_bn
│ (None, 56, 56, 96)
│
384 │ block2a_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_activation
│ (None, 56, 56, 96)
│
0 │ block2a_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_se_squeeze
│ (None, 96)
│
0 │ block2a_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_se_reshape (Reshape) │ (None, 1, 1, 96)
│
0 │ block2a_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_se_reduce (Conv2D)
│ (None, 1, 1, 4)
│
388 │ block2a_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_se_expand (Conv2D)
│ (None, 1, 1, 96)
│
480 │ block2a_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_se_excite (Multiply) │ (None, 56, 56, 96)
│
0 │ block2a_activation[0][0], │
│
│
│
│ block2a_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ block2a_project_conv (Conv2D) │ (None, 56, 56, 24)
│
2,304 │ block2a_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2a_project_bn
│ (None, 56, 56, 24)
│
96 │ block2a_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_expand_conv (Conv2D) │ (None, 56, 56, 144)
│
3,456 │ block2a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_expand_bn
│ (None, 56, 56, 144)
│
576 │ block2b_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_expand_activation
│ (None, 56, 56, 144)
│
0 │ block2b_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_dwconv
│ (None, 56, 56, 144)
│
1,296 │ block2b_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_bn
│ (None, 56, 56, 144)
│
576 │ block2b_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_activation
│ (None, 56, 56, 144)
│
0 │ block2b_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_se_squeeze
│ (None, 144)
│
0 │ block2b_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_se_reshape (Reshape) │ (None, 1, 1, 144)
│
0 │ block2b_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_se_reduce (Conv2D)
│ (None, 1, 1, 6)
│
870 │ block2b_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_se_expand (Conv2D)
│ (None, 1, 1, 144)
│
1,008 │ block2b_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_se_excite (Multiply) │ (None, 56, 56, 144)
│
0 │ block2b_activation[0][0], │
│
│
│
│ block2b_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_project_conv (Conv2D) │ (None, 56, 56, 24)
│
3,456 │ block2b_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_project_bn
│ (None, 56, 56, 24)
│
96 │ block2b_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_drop (Dropout)
│ (None, 56, 56, 24)
│
0 │ block2b_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block2b_add (Add)
│ (None, 56, 56, 24)
│
0 │ block2b_drop[0][0],
│
│
│
│
│ block2a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_expand_conv (Conv2D) │ (None, 56, 56, 144)
│
3,456 │ block2b_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_expand_bn
│ (None, 56, 56, 144)
│
576 │ block3a_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ block3a_expand_activation
│ (None, 56, 56, 144)
│
0 │ block3a_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_dwconv_pad
│ (None, 59, 59, 144)
│
0 │ block3a_expand_activation… │
│ (ZeroPadding2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_dwconv
│ (None, 28, 28, 144)
│
3,600 │ block3a_dwconv_pad[0][0]
│
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_bn
│ (None, 28, 28, 144)
│
576 │ block3a_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_activation
│ (None, 28, 28, 144)
│
0 │ block3a_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_se_squeeze
│ (None, 144)
│
0 │ block3a_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_se_reshape (Reshape) │ (None, 1, 1, 144)
│
0 │ block3a_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_se_reduce (Conv2D)
│ (None, 1, 1, 6)
│
870 │ block3a_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_se_expand (Conv2D)
│ (None, 1, 1, 144)
│
1,008 │ block3a_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ block3a_se_excite (Multiply) │ (None, 28, 28, 144)
│
0 │ block3a_activation[0][0], │
│
│
│
│ block3a_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_project_conv (Conv2D) │ (None, 28, 28, 40)
│
5,760 │ block3a_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3a_project_bn
│ (None, 28, 28, 40)
│
160 │ block3a_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_expand_conv (Conv2D) │ (None, 28, 28, 240)
│
9,600 │ block3a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_expand_bn
│ (None, 28, 28, 240)
│
960 │ block3b_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_expand_activation
│ (None, 28, 28, 240)
│
0 │ block3b_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_dwconv
│ (None, 28, 28, 240)
│
6,000 │ block3b_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_bn
│ (None, 28, 28, 240)
│
960 │ block3b_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_activation
│ (None, 28, 28, 240)
│
0 │ block3b_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ block3b_se_squeeze
│ (None, 240)
│
0 │ block3b_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_se_reshape (Reshape) │ (None, 1, 1, 240)
│
0 │ block3b_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_se_reduce (Conv2D)
│ (None, 1, 1, 10)
│
2,410 │ block3b_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_se_expand (Conv2D)
│ (None, 1, 1, 240)
│
2,640 │ block3b_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_se_excite (Multiply) │ (None, 28, 28, 240)
│
0 │ block3b_activation[0][0], │
│
│
│
│ block3b_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_project_conv (Conv2D) │ (None, 28, 28, 40)
│
9,600 │ block3b_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_project_bn
│ (None, 28, 28, 40)
│
160 │ block3b_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_drop (Dropout)
│ (None, 28, 28, 40)
│
0 │ block3b_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block3b_add (Add)
│ (None, 28, 28, 40)
│
0 │ block3b_drop[0][0],
│
│
│
│
│ block3a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_expand_conv (Conv2D) │ (None, 28, 28, 240)
│
9,600 │ block3b_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ block4a_expand_bn
│ (None, 28, 28, 240)
│
960 │ block4a_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_expand_activation
│ (None, 28, 28, 240)
│
0 │ block4a_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_dwconv_pad
│ (None, 29, 29, 240)
│
0 │ block4a_expand_activation… │
│ (ZeroPadding2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_dwconv
│ (None, 14, 14, 240)
│
2,160 │ block4a_dwconv_pad[0][0]
│
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_bn
│ (None, 14, 14, 240)
│
960 │ block4a_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_activation
│ (None, 14, 14, 240)
│
0 │ block4a_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_se_squeeze
│ (None, 240)
│
0 │ block4a_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_se_reshape (Reshape) │ (None, 1, 1, 240)
│
0 │ block4a_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_se_reduce (Conv2D)
│ (None, 1, 1, 10)
│
2,410 │ block4a_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ block4a_se_expand (Conv2D)
│ (None, 1, 1, 240)
│
2,640 │ block4a_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_se_excite (Multiply) │ (None, 14, 14, 240)
│
0 │ block4a_activation[0][0], │
│
│
│
│ block4a_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_project_conv (Conv2D) │ (None, 14, 14, 80)
│
19,200 │ block4a_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4a_project_bn
│ (None, 14, 14, 80)
│
320 │ block4a_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_expand_conv (Conv2D) │ (None, 14, 14, 480)
│
38,400 │ block4a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_expand_bn
│ (None, 14, 14, 480)
│
1,920 │ block4b_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_expand_activation
│ (None, 14, 14, 480)
│
0 │ block4b_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_dwconv
│ (None, 14, 14, 480)
│
4,320 │ block4b_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_bn
│ (None, 14, 14, 480)
│
1,920 │ block4b_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_activation
│ (None, 14, 14, 480)
│

0 │ block4b_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_se_squeeze
│ (None, 480)
│
0 │ block4b_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_se_reshape (Reshape) │ (None, 1, 1, 480)
│
0 │ block4b_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_se_reduce (Conv2D)
│ (None, 1, 1, 20)
│
9,620 │ block4b_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_se_expand (Conv2D)
│ (None, 1, 1, 480)
│
10,080 │ block4b_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_se_excite (Multiply) │ (None, 14, 14, 480)
│
0 │ block4b_activation[0][0], │
│
│
│
│ block4b_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_project_conv (Conv2D) │ (None, 14, 14, 80)
│
38,400 │ block4b_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_project_bn
│ (None, 14, 14, 80)
│
320 │ block4b_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_drop (Dropout)
│ (None, 14, 14, 80)
│
0 │ block4b_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4b_add (Add)
│ (None, 14, 14, 80)
│
0 │ block4b_drop[0][0],
│
│
│
│
│ block4a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ block4c_expand_conv (Conv2D) │ (None, 14, 14, 480)
│
38,400 │ block4b_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_expand_bn
│ (None, 14, 14, 480)
│
1,920 │ block4c_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_expand_activation
│ (None, 14, 14, 480)
│
0 │ block4c_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_dwconv
│ (None, 14, 14, 480)
│
4,320 │ block4c_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_bn
│ (None, 14, 14, 480)
│
1,920 │ block4c_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_activation
│ (None, 14, 14, 480)
│
0 │ block4c_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_se_squeeze
│ (None, 480)
│
0 │ block4c_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_se_reshape (Reshape) │ (None, 1, 1, 480)
│
0 │ block4c_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_se_reduce (Conv2D)
│ (None, 1, 1, 20)
│
9,620 │ block4c_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_se_expand (Conv2D)
│ (None, 1, 1, 480)
│

10,080 │ block4c_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_se_excite (Multiply) │ (None, 14, 14, 480)
│
0 │ block4c_activation[0][0], │
│
│
│
│ block4c_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_project_conv (Conv2D) │ (None, 14, 14, 80)
│
38,400 │ block4c_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_project_bn
│ (None, 14, 14, 80)
│
320 │ block4c_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_drop (Dropout)
│ (None, 14, 14, 80)
│
0 │ block4c_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block4c_add (Add)
│ (None, 14, 14, 80)
│
0 │ block4c_drop[0][0],
│
│
│
│
│ block4b_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_expand_conv (Conv2D) │ (None, 14, 14, 480)
│
38,400 │ block4c_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_expand_bn
│ (None, 14, 14, 480)
│
1,920 │ block5a_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_expand_activation
│ (None, 14, 14, 480)
│
0 │ block5a_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_dwconv
│ (None, 14, 14, 480)
│
12,000 │ block5a_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_bn
│ (None, 14, 14, 480)
│
1,920 │ block5a_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_activation
│ (None, 14, 14, 480)
│
0 │ block5a_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_se_squeeze
│ (None, 480)
│
0 │ block5a_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_se_reshape (Reshape) │ (None, 1, 1, 480)
│
0 │ block5a_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_se_reduce (Conv2D)
│ (None, 1, 1, 20)
│
9,620 │ block5a_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_se_expand (Conv2D)
│ (None, 1, 1, 480)
│
10,080 │ block5a_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_se_excite (Multiply) │ (None, 14, 14, 480)
│
0 │ block5a_activation[0][0], │
│
│
│
│ block5a_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_project_conv (Conv2D) │ (None, 14, 14, 112)
│
53,760 │ block5a_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5a_project_bn
│ (None, 14, 14, 112)
│
448 │ block5a_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_expand_conv (Conv2D) │ (None, 14, 14, 672)
│

75,264 │ block5a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_expand_bn
│ (None, 14, 14, 672)
│
2,688 │ block5b_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_expand_activation
│ (None, 14, 14, 672)
│
0 │ block5b_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_dwconv
│ (None, 14, 14, 672)
│
16,800 │ block5b_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_bn
│ (None, 14, 14, 672)
│
2,688 │ block5b_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_activation
│ (None, 14, 14, 672)
│
0 │ block5b_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_se_squeeze
│ (None, 672)
│
0 │ block5b_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_se_reshape (Reshape) │ (None, 1, 1, 672)
│
0 │ block5b_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_se_reduce (Conv2D)
│ (None, 1, 1, 28)
│
18,844 │ block5b_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_se_expand (Conv2D)
│ (None, 1, 1, 672)
│
19,488 │ block5b_se_reduce[0][0]
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_se_excite (Multiply) │ (None, 14, 14, 672)
│
0 │ block5b_activation[0][0], │
│
│
│
│ block5b_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_project_conv (Conv2D) │ (None, 14, 14, 112)
│
75,264 │ block5b_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_project_bn
│ (None, 14, 14, 112)
│
448 │ block5b_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_drop (Dropout)
│ (None, 14, 14, 112)
│
0 │ block5b_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5b_add (Add)
│ (None, 14, 14, 112)
│
0 │ block5b_drop[0][0],
│
│
│
│
│ block5a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_expand_conv (Conv2D) │ (None, 14, 14, 672)
│
75,264 │ block5b_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_expand_bn
│ (None, 14, 14, 672)
│
2,688 │ block5c_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_expand_activation
│ (None, 14, 14, 672)
│
0 │ block5c_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_dwconv
│ (None, 14, 14, 672)
│
16,800 │ block5c_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ block5c_bn
│ (None, 14, 14, 672)
│
2,688 │ block5c_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_activation
│ (None, 14, 14, 672)
│
0 │ block5c_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_se_squeeze
│ (None, 672)
│
0 │ block5c_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_se_reshape (Reshape) │ (None, 1, 1, 672)
│
0 │ block5c_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_se_reduce (Conv2D)
│ (None, 1, 1, 28)
│
18,844 │ block5c_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_se_expand (Conv2D)
│ (None, 1, 1, 672)
│
19,488 │ block5c_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_se_excite (Multiply) │ (None, 14, 14, 672)
│
0 │ block5c_activation[0][0], │
│
│
│
│ block5c_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_project_conv (Conv2D) │ (None, 14, 14, 112)
│
75,264 │ block5c_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_project_bn
│ (None, 14, 14, 112)
│
448 │ block5c_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_drop (Dropout)
│ (None, 14, 14, 112)
│
0 │ block5c_project_bn[0][0]
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block5c_add (Add)
│ (None, 14, 14, 112)
│
0 │ block5c_drop[0][0],
│
│
│
│
│ block5b_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_expand_conv (Conv2D) │ (None, 14, 14, 672)
│
75,264 │ block5c_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_expand_bn
│ (None, 14, 14, 672)
│
2,688 │ block6a_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_expand_activation
│ (None, 14, 14, 672)
│
0 │ block6a_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_dwconv_pad
│ (None, 17, 17, 672)
│
0 │ block6a_expand_activation… │
│ (ZeroPadding2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_dwconv
│ (None, 7, 7, 672)
│
16,800 │ block6a_dwconv_pad[0][0]
│
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_bn
│ (None, 7, 7, 672)
│
2,688 │ block6a_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_activation
│ (None, 7, 7, 672)
│
0 │ block6a_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_se_squeeze
│ (None, 672)
│

0 │ block6a_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_se_reshape (Reshape) │ (None, 1, 1, 672)
│
0 │ block6a_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_se_reduce (Conv2D)
│ (None, 1, 1, 28)
│
18,844 │ block6a_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_se_expand (Conv2D)
│ (None, 1, 1, 672)
│
19,488 │ block6a_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_se_excite (Multiply) │ (None, 7, 7, 672)
│
0 │ block6a_activation[0][0], │
│
│
│
│ block6a_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_project_conv (Conv2D) │ (None, 7, 7, 192)
│
129,024 │ block6a_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6a_project_bn
│ (None, 7, 7, 192)
│
768 │ block6a_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_expand_conv (Conv2D) │ (None, 7, 7, 1152)
│
221,184 │ block6a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_expand_bn
│ (None, 7, 7, 1152)
│
4,608 │ block6b_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_expand_activation
│ (None, 7, 7, 1152)
│
0 │ block6b_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ block6b_dwconv
│ (None, 7, 7, 1152)
│
28,800 │ block6b_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_bn
│ (None, 7, 7, 1152)
│
4,608 │ block6b_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_activation
│ (None, 7, 7, 1152)
│
0 │ block6b_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_se_squeeze
│ (None, 1152)
│
0 │ block6b_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_se_reshape (Reshape) │ (None, 1, 1, 1152)
│
0 │ block6b_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_se_reduce (Conv2D)
│ (None, 1, 1, 48)
│
55,344 │ block6b_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_se_expand (Conv2D)
│ (None, 1, 1, 1152)
│
56,448 │ block6b_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_se_excite (Multiply) │ (None, 7, 7, 1152)
│
0 │ block6b_activation[0][0], │
│
│
│
│ block6b_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_project_conv (Conv2D) │ (None, 7, 7, 192)
│
221,184 │ block6b_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_project_bn
│ (None, 7, 7, 192)
│
768 │ block6b_project_conv[0][0] │
│ (BatchNormalization)
│
│

│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_drop (Dropout)
│ (None, 7, 7, 192)
│
0 │ block6b_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6b_add (Add)
│ (None, 7, 7, 192)
│
0 │ block6b_drop[0][0],
│
│
│
│
│ block6a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_expand_conv (Conv2D) │ (None, 7, 7, 1152)
│
221,184 │ block6b_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_expand_bn
│ (None, 7, 7, 1152)
│
4,608 │ block6c_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_expand_activation
│ (None, 7, 7, 1152)
│
0 │ block6c_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_dwconv
│ (None, 7, 7, 1152)
│
28,800 │ block6c_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_bn
│ (None, 7, 7, 1152)
│
4,608 │ block6c_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_activation
│ (None, 7, 7, 1152)
│
0 │ block6c_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_se_squeeze
│ (None, 1152)
│
0 │ block6c_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│

│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_se_reshape (Reshape) │ (None, 1, 1, 1152)
│
0 │ block6c_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_se_reduce (Conv2D)
│ (None, 1, 1, 48)
│
55,344 │ block6c_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_se_expand (Conv2D)
│ (None, 1, 1, 1152)
│
56,448 │ block6c_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_se_excite (Multiply) │ (None, 7, 7, 1152)
│
0 │ block6c_activation[0][0], │
│
│
│
│ block6c_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_project_conv (Conv2D) │ (None, 7, 7, 192)
│
221,184 │ block6c_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_project_bn
│ (None, 7, 7, 192)
│
768 │ block6c_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_drop (Dropout)
│ (None, 7, 7, 192)
│
0 │ block6c_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6c_add (Add)
│ (None, 7, 7, 192)
│
0 │ block6c_drop[0][0],
│
│
│
│
│ block6b_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_expand_conv (Conv2D) │ (None, 7, 7, 1152)
│
221,184 │ block6c_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_expand_bn
│ (None, 7, 7, 1152)
│
4,608 │ block6d_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_expand_activation
│ (None, 7, 7, 1152)
│
0 │ block6d_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_dwconv
│ (None, 7, 7, 1152)
│
28,800 │ block6d_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_bn
│ (None, 7, 7, 1152)
│
4,608 │ block6d_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_activation
│ (None, 7, 7, 1152)
│
0 │ block6d_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_se_squeeze
│ (None, 1152)
│
0 │ block6d_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_se_reshape (Reshape) │ (None, 1, 1, 1152)
│
0 │ block6d_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_se_reduce (Conv2D)
│ (None, 1, 1, 48)
│
55,344 │ block6d_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_se_expand (Conv2D)
│ (None, 1, 1, 1152)
│
56,448 │ block6d_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_se_excite (Multiply) │ (None, 7, 7, 1152)
│
0 │ block6d_activation[0][0], │
│
│
│
│ block6d_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────

────────┼────────────────────────────┤
│ block6d_project_conv (Conv2D) │ (None, 7, 7, 192)
│
221,184 │ block6d_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_project_bn
│ (None, 7, 7, 192)
│
768 │ block6d_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_drop (Dropout)
│ (None, 7, 7, 192)
│
0 │ block6d_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block6d_add (Add)
│ (None, 7, 7, 192)
│
0 │ block6d_drop[0][0],
│
│
│
│
│ block6c_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_expand_conv (Conv2D) │ (None, 7, 7, 1152)
│
221,184 │ block6d_add[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_expand_bn
│ (None, 7, 7, 1152)
│
4,608 │ block7a_expand_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_expand_activation
│ (None, 7, 7, 1152)
│
0 │ block7a_expand_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_dwconv
│ (None, 7, 7, 1152)
│
10,368 │ block7a_expand_activation… │
│ (DepthwiseConv2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_bn
│ (None, 7, 7, 1152)
│
4,608 │ block7a_dwconv[0][0]
│
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤

│ block7a_activation
│ (None, 7, 7, 1152)
│
0 │ block7a_bn[0][0]
│
│ (Activation)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_se_squeeze
│ (None, 1152)
│
0 │ block7a_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_se_reshape (Reshape) │ (None, 1, 1, 1152)
│
0 │ block7a_se_squeeze[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_se_reduce (Conv2D)
│ (None, 1, 1, 48)
│
55,344 │ block7a_se_reshape[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_se_expand (Conv2D)
│ (None, 1, 1, 1152)
│
56,448 │ block7a_se_reduce[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_se_excite (Multiply) │ (None, 7, 7, 1152)
│
0 │ block7a_activation[0][0], │
│
│
│
│ block7a_se_expand[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_project_conv (Conv2D) │ (None, 7, 7, 320)
│
368,640 │ block7a_se_excite[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ block7a_project_bn
│ (None, 7, 7, 320)
│
1,280 │ block7a_project_conv[0][0] │
│ (BatchNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ top_conv (Conv2D)
│ (None, 7, 7, 1280)
│
409,600 │ block7a_project_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ radar_input (InputLayer)
│ (None, 100, 11)
│
0 │ │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ top_bn (BatchNormalization)
│ (None, 7, 7, 1280)
│

5,120 │ top_conv[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_6 (Dense)
│ (None, 100, 256)
│
3,072 │ radar_input[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ top_activation (Activation)
│ (None, 7, 7, 1280)
│
0 │ top_bn[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_7 (Dense)
│ (None, 100, 128)
│
32,896 │ dense_6[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ global_average_pooling2d_2
│ (None, 1280)
│
0 │ top_activation[0][0]
│
│ (GlobalAveragePooling2D)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_8 (Dense)
│ (None, 100, 1280)
│
165,120 │ dense_7[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ reshape (Reshape)
│ (None, 1, 1280)
│
0 │ global_average_pooling2d_… │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ multi_head_attention
│ [(None, 1, 1280), (None, │
2,624,256 │ dense_8[0][0],
│
│ (MultiHeadAttention)
│ 4, 1, 1)]
│
│ reshape[0][0],
│
│
│
│
│ dense_8[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ layer_normalization
│ (None, 1, 1280)
│
2,560 │ multi_head_attention[0][0] │
│ (LayerNormalization)
│
│
│
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ reshape_1 (Reshape)
│ (None, 1280)
│
0 │ layer_normalization[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_9 (Dense)
│ (None, 256)
│
327,936 │ reshape_1[0][0]
│

├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_10 (Dense)
│ (None, 128)
│
32,896 │ dense_9[0][0]
│
├───────────────────────────────┼───────────────────────────┼─────────
────────┼────────────────────────────┤
│ dense_11 (Dense)
│ (None, 1)
│
129 │ dense_10[0][0]
│
└───────────────────────────────┴───────────────────────────┴─────────
────────┴────────────────────────────┘
Total params: 7,238,436 (27.61 MB)
Trainable params: 3,188,865 (12.16 MB)
Non-trainable params: 4,049,571 (15.45 MB)
# Train the advanced fusion model
history = advanced_fusion_model.fit(
[camera_train_data, radar_train_data], # Input: camera and radar
training data
train_labels,
# Output: training labels
epochs=10,
batch_size=32,
validation_data=([camera_val_data, radar_val_data], val_labels)
)
Epoch 1/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 264s 2s/step - accuracy: 0.4880 - loss:
0.7049 - val_accuracy: 0.4975 - val_loss: 0.7057
Epoch 2/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 1028s 10s/step - accuracy: 0.5152 - loss:
0.6992 - val_accuracy: 0.5025 - val_loss: 0.6933
Epoch 3/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 1993s 20s/step - accuracy: 0.4849 - loss:
0.7042 - val_accuracy: 0.5025 - val_loss: 0.6931
Epoch 4/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 434s 4s/step - accuracy: 0.4819 - loss:
0.7015 - val_accuracy: 0.4975 - val_loss: 0.6940
Epoch 5/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 332s 3s/step - accuracy: 0.4981 - loss:
0.6942 - val_accuracy: 0.5025 - val_loss: 0.6943
Epoch 6/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 1259s 12s/step - accuracy: 0.5114 - loss:
0.7018 - val_accuracy: 0.5025 - val_loss: 0.6983
Epoch 7/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 272s 3s/step - accuracy: 0.5144 - loss:
0.6946 - val_accuracy: 0.4975 - val_loss: 0.6932
Epoch 8/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 284s 3s/step - accuracy: 0.5040 - loss:

0.6933 - val_accuracy: 0.4975 - val_loss: 0.6932
Epoch 9/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 320s 3s/step - accuracy: 0.4874 - loss:
0.6932 - val_accuracy: 0.5025 - val_loss: 0.6931
Epoch 10/10
102/102 ━━━━━━━━━━━━━━━━━━━━ 262s 3s/step - accuracy: 0.5018 - loss:
0.6932 - val_accuracy: 0.5025 - val_loss: 0.6931
from sklearn.metrics import accuracy_score, precision_score,
recall_score, f1_score
# Make predictions on the validation set
y_pred_prob = advanced_fusion_model.predict([camera_val_data,
radar_val_data])
y_pred = (y_pred_prob > 0.5).astype("int32")
# Calculate accuracy, precision, recall, and F1 score
accuracy = accuracy_score(val_labels, y_pred)
precision = precision_score(val_labels, y_pred, zero_division=1)
recall = recall_score(val_labels, y_pred, zero_division=1)
f1 = f1_score(val_labels, y_pred, zero_division=1)
# Print the evaluation metrics
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")
26/26 ━━━━━━━━━━━━━━━━━━━━ 44s 2s/step
Accuracy: 0.50
Precision: 0.50
Recall: 1.00
F1 Score: 0.67
## 9. Visualization
##

A. Precision-Recall Curve

from sklearn.metrics import precision_recall_curve
# Compute precision-recall curve
precision, recall, _ = precision_recall_curve(val_labels, y_pred_prob)
# Plot Precision-Recall curve
plt.figure()
plt.plot(recall, precision, color='b', lw=2)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.show()

##

B. Bounding Box Visualization

import cv2
import matplotlib.pyplot as plt
# Example: Assuming `predicted_boxes` contains [x_min, y_min, x_max,
y_max] for each image
# You should replace `predicted_boxes` and `true_boxes` with your
actual data
# Sample data: Replace with actual bounding box coordinates and image
predicted_boxes = [[50, 50, 200, 200], [30, 30, 180, 180]] # Format:
[x_min, y_min, x_max, y_max]
true_boxes = [[55, 55, 195, 195], [35, 35, 170, 170]] # True boxes
(if available)
image = camera_val_data[0] # Replace with an actual image from your
data
# Convert image from RGB (Keras format) to BGR (OpenCV format)
image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
# Draw predicted bounding boxes in blue
for box in predicted_boxes:

x_min, y_min, x_max, y_max = box
cv2.rectangle(image_bgr, (x_min, y_min), (x_max, y_max), (255, 0,
0), 2) # Blue for predicted
# Draw true bounding boxes in green (optional, if available)
for box in true_boxes:
x_min, y_min, x_max, y_max = box
cv2.rectangle(image_bgr, (x_min, y_min), (x_max, y_max), (0, 255,
0), 2) # Green for true
# Convert image back to RGB and plot it
image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
plt.imshow(image_rgb)
plt.title("Bounding Box Visualization")
plt.show()
Clipping input data to the valid range for imshow with RGB data
([0..1] for floats or [0..255] for integers). Got range [123.68..255.0].

##

C. Box Plot of Metrics

accuracy_scores = [0.50]
precision_scores = [0.50]

recall_scores = [1.00]
f1_scores = [0.67]
import matplotlib.pyplot as plt
# Combine data into a list of lists
metrics_data = [accuracy_scores, precision_scores, recall_scores,
f1_scores]
# Create labels for the box plot
metric_labels = ['Accuracy', 'Precision', 'Recall', 'F1-score']
# Plot the box plot
plt.figure(figsize=(5, 5))
plt.boxplot(metrics_data, labels=metric_labels)
plt.title('Evaluation Metrics Distribution')
plt.ylabel('Score')
plt.grid(True)
# Show the plot
plt.show()
C:\Users\siric\AppData\Local\Temp\ipykernel_6816\3249784035.py:11:
MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has
been renamed 'tick_labels' since Matplotlib 3.9; support for the old
name will be dropped in 3.11.
plt.boxplot(metrics_data, labels=metric_labels)

### Objective-4 - Compare and Validate the performance of the multisensor fusion system
## Comparison Setup
camera_precision = 0.56
radar_precision = 0.95
fusion_precision = 0.50
improvement_fusion_vs_camera = fusion_precision - camera_precision
improvement_fusion_vs_radar = fusion_precision - radar_precision
print(f"Precision improvement (Fusion vs Camera ):
{improvement_fusion_vs_camera}")
print(f"Precision improvement (Fusion vs Radar):
{improvement_fusion_vs_radar}")
Precision improvement (Fusion vs Camera ): -0.06000000000000005
Precision improvement (Fusion vs Radar): -0.44999999999999996
## Collecting Multiple Metrics
camera_metrics = {
'accuracy': [0.56],
'precision': [0.56],
'recall': [0.93],
'f1_score': [0.70]
}
radar_metrics = {
'accuracy': [0.98],
'precision': [0.95],
'recall': [0.84],
'f1_score': [0.89]
}
fusion_metrics = {
'accuracy': [0.50],
'precision': [0.50],
'recall': [1.00],
'f1_score': [0.67]
}
# Calculate differences between fusion and other models for each
metric
def calculate_difference(metric_fusion, metric_other):
return metric_fusion - metric_other
metrics = ['accuracy', 'precision', 'recall', 'f1_score']
for metric in metrics:

diff_camera = calculate_difference(fusion_metrics[metric][0],
camera_metrics[metric][0])
diff_radar = calculate_difference(fusion_metrics[metric][0],
radar_metrics[metric][0])
print(f"Difference in {metric.capitalize()} (Fusion vs Camera):
{diff_camera}")
print(f"Difference in {metric.capitalize()} (Fusion vs Radar):
{diff_radar}")
Difference in Accuracy (Fusion vs Camera): -0.06000000000000005
Difference in Accuracy (Fusion vs Radar): -0.48
Difference in Precision (Fusion vs Camera): -0.06000000000000005
Difference in Precision (Fusion vs Radar): -0.44999999999999996
Difference in Recall (Fusion vs Camera): 0.06999999999999995
Difference in Recall (Fusion vs Radar): 0.16000000000000003
Difference in F1_score (Fusion vs Camera): -0.029999999999999916
Difference in F1_score (Fusion vs Radar): -0.21999999999999997
## Visualization of Comparison
import matplotlib.pyplot as plt
import numpy as np
# Prepare data for visualization
metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
camera_scores = [camera_metrics['accuracy'][0],
camera_metrics['precision'][0], camera_metrics['recall'][0],
camera_metrics['f1_score'][0]]
radar_scores = [radar_metrics['accuracy'][0],
radar_metrics['precision'][0], radar_metrics['recall'][0],
radar_metrics['f1_score'][0]]
fusion_scores = [fusion_metrics['accuracy'][0],
fusion_metrics['precision'][0], fusion_metrics['recall'][0],
fusion_metrics['f1_score'][0]]
# Set the width for the bars
bar_width = 0.25
r1 = np.arange(len(metrics))
r2 = [x + bar_width for x in r1]
r3 = [x + bar_width for x in r2]
# Create the bar chart
plt.bar(r1, camera_scores, color='blue', width=bar_width,
edgecolor='grey', label='Camera')
plt.bar(r2, radar_scores, color='red', width=bar_width,
edgecolor='grey', label='Radar')
plt.bar(r3, fusion_scores, color='green', width=bar_width,
edgecolor='grey', label='Fusion')

# Add labels and title
plt.xlabel('Metrics', fontweight='bold')
plt.xticks([r + bar_width for r in range(len(metrics))], metrics)
plt.legend()
plt.title('Model Performance Comparison')
# Display the plot
plt.show()

